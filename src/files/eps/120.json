{"dialog_idx": {"tim ferriss": [0, 1, 2, 3, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495, 496, 497, 498, 499, 500, 501, 502, 503, 504, 505, 506, 507, 508, 509, 510, 511, 512, 513, 514, 515, 516, 517, 518, 519, 520, 521, 522, 523, 524, 525, 526, 527, 528, 529, 530, 531, 532, 533, 534, 535, 536, 537, 538, 539, 540, 541, 542, 543, 544, 545, 546, 547, 548, 549, 550, 551, 552, 553, 554, 555, 556, 557, 558, 559, 560, 561, 562, 563, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 575, 576, 577, 578, 579, 580, 581, 582, 583, 584, 585, 586, 587, 588, 589, 590, 591, 592, 593, 594, 595, 596, 597, 598, 599, 600, 601, 602, 603, 604, 605, 606, 607, 608, 609, 610, 611, 612, 613, 614, 615, 616, 617, 618, 619, 620, 621, 622, 623, 624, 625, 626, 627, 628, 629, 630, 631, 632, 633, 634, 635, 636, 637, 638, 639, 640, 641, 642, 643, 644, 645, 646, 647, 648, 649, 650, 651, 652, 653, 654, 655, 656, 657, 658, 659, 660, 661, 662, 663, 664, 665, 666, 667, 668, 669, 670, 671, 672, 673, 674, 675, 676, 677, 678, 679, 680, 681, 682, 683, 684, 685, 686, 687, 688, 689, 690, 691, 692, 693, 694, 695, 696, 697, 698, 699, 700, 701, 702, 703, 704, 705, 706, 707, 708, 709, 710, 711, 712, 713, 714, 715, 716, 717, 718, 719, 720, 721, 722, 723, 724, 725, 726, 727, 728, 729, 730, 731, 732, 733, 734, 735, 736, 737, 738, 739, 740, 741, 742, 743, 744, 745, 746, 747, 748, 749, 750, 751, 752, 753, 754, 755, 756, 757, 758, 759, 760, 761, 762, 763, 764, 765, 766, 767, 768, 769, 770, 771, 772, 773, 774, 775, 776, 777, 778, 779, 780, 781, 782, 783, 784, 785, 786, 787, 788, 789, 790, 791, 792, 793, 794, 795, 796, 797, 798, 799, 800, 801, 802, 803, 804, 805, 806, 807, 808, 809, 810, 811, 812, 813, 814, 815, 816, 817, 818, 819, 820, 821, 822, 823, 824, 825, 826, 827, 828, 829, 830, 831, 832, 833, 834, 835, 836, 837, 838, 839, 840, 841, 842, 843, 844, 845, 846, 847, 848, 849, 850, 851, 852, 853, 854, 855, 856, 857, 858, 859, 860, 861, 862, 863, 864, 865, 866, 867, 868, 869, 870, 871, 872, 873, 874, 875, 876, 877, 878, 879, 880, 881, 882, 883, 884, 885, 886, 887, 888, 889, 890, 891, 892, 893, 894, 895, 896, 897, 898, 899, 900, 901, 902, 903, 904, 905, 906, 907, 908, 909, 910, 911, 912, 913, 914, 915, 916, 917, 918, 919, 920, 921, 922, 923, 924, 925, 926, 927, 928, 929, 930, 931, 932, 933, 934, 935, 936, 937, 938, 939, 940, 941, 942, 943, 944, 945, 946, 947, 948, 949, 950, 951, 952, 953, 954, 955, 956, 957, 958, 959, 960, 961, 962, 963, 964, 965, 966, 967, 968, 969, 970, 971, 972, 973, 974, 975, 976, 977, 978, 979, 980, 981, 982, 983, 984, 985, 986, 987, 988, 989, 990, 991, 992, 993, 994, 995, 996, 997, 998, 999, 1000, 1001, 1002, 1003, 1004, 1005, 1006, 1007, 1008, 1009, 1010, 1011, 1012, 1013, 1014, 1015, 1016, 1017, 1018, 1019, 1020, 1021, 1022, 1023, 1024, 1025, 1026, 1027, 1028, 1029, 1030, 1031, 1032, 1033, 1034, 1035, 1036, 1037, 1038, 1039, 1040, 1041, 1042, 1043, 1044, 1045, 1046, 1047, 1048, 1049, 1050, 1051, 1052, 1053, 1054, 1055, 1056, 1057, 1058, 1059, 1060, 1061, 1062, 1063, 1064, 1065, 1066, 1067, 1068, 1069, 1070, 1071, 1072, 1073, 1074, 1075, 1076, 1077, 1078, 1079, 1080, 1081, 1082, 1083, 1084, 1085, 1086, 1087, 1088, 1089, 1090, 1091, 1092, 1093, 1094, 1095, 1096, 1097, 1098, 1099, 1100, 1101, 1102, 1103, 1104, 1105, 1106, 1107, 1108, 1109, 1110, 1111, 1112, 1113, 1114, 1115, 1116, 1117, 1118, 1119, 1120, 1121, 1122, 1123, 1124, 1125, 1126, 1127, 1128, 1129, 1130, 1131, 1132, 1133, 1134, 1135, 1136, 1137, 1138, 1139, 1140, 1141, 1142, 1143, 1144, 1145, 1146, 1147, 1148, 1149, 1150, 1151, 1152, 1153, 1154, 1155, 1156, 1157, 1158, 1159, 1160, 1161, 1162, 1163, 1164, 1165, 1166, 1167, 1168, 1169, 1170, 1171, 1172, 1173, 1174, 1175, 1176, 1177, 1178, 1179, 1180, 1181, 1182, 1183, 1184, 1185, 1186, 1187, 1188, 1189, 1190, 1191, 1192, 1193, 1194, 1195, 1196, 1197, 1198, 1199, 1200, 1201, 1202, 1203, 1204, 1205, 1206, 1207, 1208, 1209, 1210, 1211, 1212, 1213, 1214, 1215, 1216, 1217, 1218, 1219, 1220, 1221, 1222, 1223, 1224, 1225, 1226, 1227, 1228, 1229, 1230, 1231, 1232, 1233, 1234, 1235, 1236, 1237, 1238, 1239, 1240, 1241, 1242, 1243, 1244, 1245, 1246, 1247, 1248, 1249, 1250, 1251, 1252, 1253, 1254, 1255, 1256, 1257, 1258, 1259, 1260, 1261, 1262, 1263, 1264, 1265, 1266, 1267, 1268, 1269, 1270, 1271, 1272, 1273, 1274, 1275, 1276, 1277, 1278, 1279, 1280, 1281, 1282, 1283, 1284, 1285, 1286, 1287, 1288, 1289, 1290, 1291, 1292, 1293, 1294, 1295, 1296, 1297, 1298, 1299, 1300, 1301, 1302, 1303, 1304, 1305, 1306, 1307, 1308, 1309, 1310, 1311, 1312, 1313, 1314, 1315, 1316, 1317, 1318, 1319, 1320, 1321, 1322, 1323, 1324, 1325, 1326, 1327, 1328, 1329, 1330, 1331, 1332, 1333, 1334, 1335, 1336, 1337, 1338, 1339, 1340, 1341, 1342, 1343, 1344, 1345, 1346, 1347, 1348, 1349, 1350, 1351, 1352, 1353, 1354, 1355], "will macaskill": [4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22]}, "episode_num": 120, "file_type": "pdf", "guests": ["will macaskill"], "num_pages": 55, "num_sentences": 1356, "num_words": 22868, "raw_text": "tim ferriss: hello, ladies and germs, this is tim ferriss, and welcome to another episode of the tim ferriss show. i am looking out over a highway from a hotel next to jfk because i forgot my passport in california and missed my flight. in any case, on this show, it is always my job to try to deconstruct world-class performers and identify the routines, the habits, the decisions that help them to become who they are. in this episode, we have a really fun guest, will macaskill. will macaskill is an associate professor in philosophy at lincoln college, which is at oxford. he is 28 years old, which makes him likely the youngest associate, in other words, tenured professor of philosophy in the world. he is co-founder of the effective altruism movement, which i'm a huge supporter of, and author of doing good better. he has pledged to donate everything he earns over 36k, roughly per year, to whatever charities he believes will be most effective. he has cofounded two well-known nonprofits, 80,000 hours and giving what we canand we'll get into both of those.   but more important, we will talk about the lessons he's learned, how to evaluate doing good, how to hack doing good, as you would in business. and he has been exposed to business. he is one of the few nonprofit founders who have gone through y combinator, which is effectively the harvard navy seal equivalent for startup incubators based in silicon valley. and his stories are just fascinating. we talk about many different things. we cover a lot of ground, everything from artificial intelligence to why following your passion in a career is often a mistake; how on earth he became a tenured professor at his young age; thought experiments, like pascal's wager versus pascal's mugging. and even if you have no interest in nonprofits or charities, this will help teach you how to think more effectively, how to evaluate things more effectively. we'll also talk about some specifics, why donating to disaster relief or purchasing things through ethical consumerism are generally not a great way to do good.   but we talk about his story, his decisions, and there's a lot to be learned. so say hello to him on the interwebs. will is @willmacaskill, @w-i-l-l-m-a-c-a-s-k-i-l-l on twitterand please enjoy our conversation. thanks for listening.   will, welcome to the show.  william macaskill: thank you for having me on.  tim ferriss: i really appreciate you making the time. and where do we find you on the planet earth at this moment?  william macaskill: i'm at oxford in the united kingdom at the moment.  tim ferriss: and now, you are an associate professor in philosophy at lincoln college, is that right?  william macaskill: yeah, lincoln college, oxford university.  tim ferriss: and lincoln college, it's not a residential college. so for instance, at princeton, they have different residential colleges. what is the significance of the colleges within oxford?  william macaskill: yeah, it's a really big thing, actually. so almost all your teaching goes on in college, you live there, you eat there, most of your friends are there while you're a student of the university   and actually, all the colleges predate the universities. so that's really the core of your life at oxford. and then you get examined and go to lectures at the university itself.  tim ferriss: and when you'd receive a degree, is it from a particular college? do you have to attribute it to the college or it simply oxford?  william macaskill: no, the degree's just from university.  tim ferriss: got it. so let's, then, begin. you do quite a few things. when someone asks you what do you do, how do you answer that question?  william macaskill: that's right. so depending on whether i want to be low-key or not, i'll tell them i'm an associate professor of philosophy at oxford university. i'm also one of the cofounders of the effective altruism movement, where that's a community of people who are dedicated to using their time and money as effectively as possible to make the world a better place. and to that end, i cofounded a couple of nonprofits. giving what we can, which encourages people to give at least 10 percent of their incomes to the most effective charities; and 80,000 hours, named after the number of hours you typically work in your life, which is about giving advice to people to ensure that if they want to pursue a career with a big impact, they can do as much good as they can.  tim ferriss: and how do you answer the question, what makes your brand of altruism effective? and maybe we can back into that with - there was a tweet i saw at one point from bill gates, and it was \"a data nerd after my own heart,\" and he linked to an article about you. i think it was a profile in the atlantic.  william macaskill: that's [inaudible].  tim ferriss: so if you're talking to a skeptic and they say, okay, well, what makes it effective?  william macaskill: okay, yeah. so the key is that we take a scientific approach to doing well. so that's using high quality evidence, really good data, thinking about the outcomes that your outcomes do rather than just what's a really sexy intervention, or what makes you feel good, but actually what's helping people the most. and going on years of research now, as well as using careful, reflective, self-critical reasoning in order to work out what those things aren't just making a difference, but are making the most difference.  tim ferriss: and what are some common mistakes - and just so people listening understand this, this isn't a disguised sell for nonprofit donations on my part. this is a conversation that i've wanted to have with you because we have a mutual friend in ryan holliday, who is himself a philosopher of sorts, huge fan of stoic philosophy, as am i. and he is a fan of yours. and i was very interested to connect. so just for those people who were wondering if this is a dressed up sales pitch, it is not. what are common mistakes that people make when giving? and i've had many of my own struggles with providing time and money to various causes and nonprofits. maybe we'll dig into some of them specificallybut what are some common mistakes or misallocation of resources that you see very commonly?  william macaskill: so yeah. i think the biggest mistake of all is just not really thinking or doing any research at where you're donating   so i mean, imagine if someone came up to you in the street and told you about this company that they'd set up, or that they were representing, and that you should really invest in this company, and they tell you about how great the company is, and then ask you right there on the street, \"well, are you going to make an investment?\"itim ferriss: sounds like silicon valley right now.  william macaskill: well, that may be a little bit different, but. certainly, here in oxford, people would be -  tim ferriss: generally not a good idea.  william macaskill: yeah, generally not a good idea. but yet, we're happy to do that when it comes to charities. we're happy to spend our money to try and help others, but without ever actually doing the research to work out what is going to actually have the biggest impact. and there are evaluators now, like giveworld.org, that are doing this research for us so that we can actually follow their recommendations, because it does take quite a bit of time.  tim ferriss: how is giveworld.org compared to, say, charity navigator or something like that?  william macaskill: yeah. the really big difference is charity navigator focuses just on kind of the financials and just on the aspects of a charity itself, where one core part of it is how much does the charity spend on overheads?   what's the percentage spent on administration? but that's not a great metric because imagine you've got some really lousy program. you're giving away donuts to hungry police officers or something. something that's not going to do very much good. but you've got this amazingly low overhead. you're spending almost nothing on administration. well, you're still going to be a lousy charity. you can't make a lousy charity good by having a very low overhead.  tim ferriss: right, got it.  william macaskill: yeah.  tim ferriss: you're looking at these sorts of operational efficiencies, but whether something is efficient or not, it can still be very ineffective.  william macaskill: yeah, that's exactly right. so you've got to look at what program the charity's implementing as well. and there, there are absolutely huge differences. so three-quarters of social programs, when put to the test using trials, are found to have no effect at all. they just don't actually improve peoples' lives. some are even actively harmful.   but then among the ones that are good that do make a difference, there's still a vast disconnect. the best ones are hundreds of times as good as merely ones that just do some amount of good.  tim ferriss: and it seems like you are a skeptic of disaster relief. is that a fair statement? or how would you unpack that?  william macaskill: yeah. so i mean, i think funding disaster relief, it should happen for sure. when there's a massive crisis like the haitian earthquake, money should be going to it, and a lot of money, in fact. but then the question is, what should you as an individual donor do? and natural disasters, because they get press coverage and so much media attention, they're massively overfunded compared to what i'd call ongoing natural disasters like the 400,000 people who die of malaria every year. but it gets far less media coverage. and in fact, even in the case of the japanese earthquake, the japanese red cross issued a statement saying, \"we do not want any money. we do not want money. we're the fourth richest country in the worldwe have resources to deal with this problem.\"   but yet they still got five billion dollars in donations, which is about the same as got allocated to haiti, which is one of the poorest countries in the world. tim ferriss: understood. and let's take a step back from it because i know we could really dig into the sort of tactics and science and numbers behind what you do. but you are currently 28, is that right?  william macaskill: that's right.  tim ferriss: and you are a tenured professor of philosophy.  william macaskill: yeah.  tim ferriss: where does that put you on the spectrum of tenured professors of philosophy worldwide, age-wise?  william macaskill: age-wise, it's hard to verify, but i suspect i might be the youngest in the world.  tim ferriss: and to what do you attribute that? why you? it's a very competitive field, as i understand it, the philosophy.   i want to ask a question about this. philosophy post-grads have the highest gre scores out of any subject. so what are the factors that contributed to you becoming tenured at such a young age?  william macaskill: yeah. so i definitely think it's not because i'm the smartest personi'm very confident i'm not. i know lots of people who are, like have exceptionally high iqs around these places. and also not, i think, because i put in the most number of hours, because i do so much other stuff as well. but i think the two things that just - one is actually kind of understanding, really thinking about what your goals are, and understanding how is it best to achieve those goalswhich seems like it's a bit of common sense. you'd think everyone would do that. but actually, most people don't. most people spend, for example, years and years kind of slogging away just on their dissertation, on their phd, even though that's normally read by four people in the world, rather than focusing, say, on publishing really good articles, which are read by much more people and much more important in terms of doing well in their career.   and then the second aspect is just absolutely a ruthless application of the 80/20 rule, which obviously, you talk about in your bookbut just the idea that of the stuff that you do, most people do, almost all value comes in a very small number of activities. and again, i think a lot of people in academia get a lot of their time used up with busy work, so attend conferences, go to seminars, they do a lot of reading, that doesn't ultimately contribute to what they're really trying to do, which is come up with new ideas, new arguments, and really put that forward. and so, i think i have been just a lot more proactive and kind of goal-oriented in terms of the approach i take to my work.  tim ferriss: so let's get into detail with that because i know people love the details. and not surprisingly, a lot of people listening love the 80/20 principle or all applications of that.   if we rewind to your undergraduate, were you studying philosophy in undergrad?  william macaskill: yeah, that's right. i was at cambridge university as an undergrad.  tim ferriss: and what did the trajectory look like? what were the inflection points or key moments between that point and getting tenured?  william macaskill: yeah. so i think i was a lot less effective as an undergrad. i was still trying to discover how to do things effectively, and i made some big mistakes. and i remember trying to train myself to only sleep four hours a night, and that was a disaster. that was the worst year of my life. then i realized, no, actually, sleeping well and exercising well are really important in terms of having good performance. one thing i realized as an undergrad was just that you can just make so much progress just by finding someone smarter than you and learning from them. and that's exactly what i did.   someone who's now a close friend of mine just knew absolutely everything, and so i'd spend just hours talking to them.  tim ferriss: who is this?  william macaskill: so he's andreas morgenson. he also got a professorship at oxford.  tim ferriss: uh-huh. in the philosophy department.  william macaskill: in the philosophy department, that's right. so we've ended up having a very similar career trajectory. and i've been a zombie and eaten his brains every stage of the way. but then in terms of the big inflection points, i think really came - it was only when i moved to oxford to do my postgrad work that i started to get a lot more serious about this. also realizing getting funding to do philosophy postgrad is pretty hard, and realizing that there a lot of lot scholarships out there that most people have never heard of, and they actually don't therefore get that many applicants, so if you apply for them, you can actually have a bigger chance. and then i managed to get funding for my phd and extend it by a little bit more than other people do through a combination of, i think, eight different scholarships in the end.   and so doing that. and then the big thing was just from the outset, i was starting a phd thinking, okay, well, philosophy's incredibly competitive. if i do want to do this as a career, then i've really got to know what's actually expected of you, like on what basis you can get hired as a professor. and the answer is weirdly disconnected from what you typically do as a grad student. at least in philosophy, people basically judge you on the quality of your best five or 10,000 words of work, whereas your dissertation is kind of 80,000 words or something. and so if you want to really do well, then it's just about making that highest quality stuff as good as possible, and in trying to get it published in the very best journals. so it's really about optimizing for your kind of peak output, rather than just being this kind of big generalist.  tim ferriss: got it. what was your dissertation on?   and what was your best five to 10,000 words about?  william macaskill: oh. so my dissertation was about ethical uncertainty. so if you're unsure about what you ought to do. so maybe you think, okay, well, i think it's okay to eat meat, but i'm unsure about that. there are all these vegetarians around and they have these arguments and so on. and you're like, well, i don't quite know what to do. how should you act in light of that? how should you take uncertainty into account? and this was quite a strategic choice of topic as well because it's a very important topic, but almost nothing has been written about it. so i could read everything that had been written on it in about two weeks, whereas many people choose to pursue phds on something that's already had a huge amount of work done. and so that was what the phd was on. and in particular, i argued that even if you're unsure about your values, you should treat that uncertainty in the same way as if you're unsure about matters of fact, or what's going to happen.   so in the same way as if you wouldn't speed down a blind corner if there's some risk of a child playing in the street, even if you thought there was probably no one there, you still wouldn't want to risk it. in the same way, if you think, well, maybe something's wrong. i think it probably isn't, but there's a risk, and if it was, it would be very wrong. i think you should take that same course of action. you should again kind of play safe, as it were.  tim ferriss: sort of pascal's wager for life?  william macaskill: it's a little bit, yeah. it doesn't involve infinite amounts of value, though that's interesting too. but a little bit like pascal's wager for life.  tim ferriss: and then what about your peak or your best five to 10,000 words? was it the same subject, or something completely different?  william macaskill: yeah, so it was the same subject as well. and this is all quite distinct from my effective altruism stuff. but it was the same subject, and in particular, i saw there was this analogy between that sort of decision and a bunch of work that had been done in economics.   so again, this is something where you can make a progress by doing research, just by combining two different fields. because the number, the combinations of fields are just far, far greater than the number of fields themselves. and so i argued that this problem was kind of like the problem of voting. so in just the same way as this problem of if you put all these people with different preferences, and you kind of aggregate that into one social preference, or one just will of the people, as it were. and there's just a ton of that done in economics that's really interesting and often quite technical. and i said that was kind of the same as a decision under ethical uncertainty. it's like you've got all these different ethical viewpoints, and they're like different voters. and if you want to be able to make a decision between them, in light of that kind of uncertainty, you can treat them as like voters.   and you can use all the same technical apparatus that have been developed in economics and apply it to that case of ethical uncertainty.  tim ferriss: so you mentioned andreas morgenson. what other philosophers are your - idols is a strong word, but role models? people you really look up to you? alive or dead. if you have to put sort of your top five or fewer philosophers on a list, who would they be?  william macaskill: yeah. so there are two who really stand out. the first one, more of kind of an academic, is derek parfit.  tim ferriss: how do you - derek parfit?  william macaskill: parfit, yeah. p-a-r-f-i-t. and he's spent his entire life at all souls college in oxford, which is elite, even within oxford.  tim ferriss: what was the name of the college?  william macaskill: all souls college.  tim ferriss: all souls?  william macaskill: all souls, yeah. the way you get into all souls college - and andreas achieved this as well - is you have to sit 15 hours of exams.   and you have to answer questions that can be on any topic, like is china overrated? why democracy? how many people should there be? and then the final three-hour exam is just on a single word.  tim ferriss: that sounds horrible. sounds very uniquely philosophical, too, i mean, in terms of academia.  william macaskill: it's crazy. it's sort of known as the hardest exam in the world. but it gives you seven years of funding, and you can do whatever you want in those seven years.  tim ferriss: what's the name of the exam?  william macaskill: it's called the all souls prize fellowship, i think  tim ferriss: ah, okay. so derek is one.  william macaskill: he is one, and he's now 70. and he wrote a book called reasons and persons, which i think is one of the most important books written in the 20th century.  tim ferriss: could you say that one more time?  william macaskill: reasons and persons.  tim ferriss: reasons and persons.  william macaskill: yeah. and it argues, oh, a whole number of things. but two of the big things are - one is the idea that there isn't really a continuing self over time.   so there's nothing kind of fundamentally distinct between will macaskill, age 28, and will macaskill, age 70, versus will macaskill, age 28, and tim ferriss right now. there's only a kind of matter of degree between those things. and that has a whole number of implications. and actually, interestingly, it's actually quite similar to a big [inaudible] in buddhist thought. and apparently, his book has been used as a text in certain buddhist temples. they chant to it. he didn't realize this for like 30 years or something.  tim ferriss: and then he showed up, and there was some effigy to derek parfit sitting on a throne in a cave in tibet.  william macaskill: yeah, i think you're right.  tim ferriss: well, i mean, it does resonate, certainly, with certain discussions of self, right?   whether it's a contemporary like sam harris, who has a phd in neuroscience, but also a very experienced meditator who wrote waking up, or texts that are thousands of years old. i mean, the concept of a static self is something that's challenged a lot in buddhist thought, among others. so you have derek. who's your number two?  william macaskill: number two then has to be peter singer.  tim ferriss: i was going to ask you about him, yeah.  william macaskill: yeah, he's a big influence, both in terms of my thought and in terms of how i'm approaching my life, the decisions i'm making, in terms of my own career. and he has two very big, important arguments. one is for the model importance of non-human animals, and treating them much better than we do at the momentand also the importance of fighting global poverty, especially for us in rich countries using - he really argued it should be most of your income, donating that away to charities that will help improve lives or save lives among the poorest people in the world.   he argues that if you were walking past a shallow pond and a child was drowning in that pond, and you could run in and save the child and it would ruin your expensive suit that you were wearing, it would cost you a couple of thousand dollars a result, you'd obviously go and do that. you'd be, in technical terms, an asshole if you didn't. he doesn't say that. that's my interpretation of the argument. but if so, then what's the difference between that and the life that you can save in malawi right now by distributing insecticide and bed nets to save a child from malaria? and he argues there isn't a difference. and he was immensely influentialhe sold millions of books and caused a large number of people to really change their lives, including myself.  tim ferriss: so i am a peter singer fan, and i think that most people who are not, most people who protest against or picket against peter singer haven't read his work. and certainly, he has controversial stancesbut i remember when he came to princeton to teach, and there were people picketing and rolling out their disabled children and so on because they were, i think, adopting bastardized versions of what he had said from media. so as much as i like peter, i would propose - but you know what? this isn't about me. let me ask you. do you think it's really the same insomuch as walking in with a suit and rescuing a drowning child versus saving a potentially sort of faceless child across the world, of which there are potentially millions, right?   and the reason i bring it up is not to say that people shouldn't do it, but i had a conversation with - well, actually, i suppose it was a q&a of sorts with sam harris about the - i think it's called the trolley scenario, but i'm not sure.  william macaskill: oh, yeah.  tim ferriss: do you know what i'm talking about, right? so those people that are not familiar with this, the hypothetical thought exercise which is going to have a lot of real implications when we're using autonomous vehicles and programming ai and so on. so philosophy's suddenly a lot more relevant, or some of these thought exercises are more relevant than they maybe would have been imagined to become. please correct me if i'm wrong, and i think i'm just paraphrasing this, but if you had a railroad track, and you could flip a switch for it to go down one track that was split to the left, and another that was split to the right. there's one kind of fat man on the left, and there are four people on the right, and you have to throw the switch.   do you throw the switch to the one person or the four? and people say, of course, that they would switch it to the one. but then the second scenario i think of, and there may be more, is if you had to push the fat man off of a bridge so he landed on the track and was an obstacle that then prevented four people from dying, would you do it? and all of a sudden, the percentages change very dramatically, right? and even though the utilitarian philosophical outcome is on paper the same, right? and i know i'm kind of brain vomiting at you, but this is something i've really grappled with.  so peter singer had a cover story. i believe it was the new york times magazine, sunday edition. huge piece on basically redistributing wealth for greater good. and yet, i couldn't necessarily point to a huge change in donation behavior after that article.   so why don't more people donate, right? because if i looked at my 10 friends, a given 10 friends who i'd consider good human beings, who have money, they would save the drowning child, but they're not going to send - if for the same reason that i think they're afraid of opening the floodgates. if they donate to one child, does it not then follow they should donate all of the money that they have to save not one child, but as many as they can afford to save? and they get themselves into a very hairy position where they feel like they can't enjoy the fruit of their labor because of the guilt that they feel. does that make sense?  william macaskill: yeah, so -  tim ferriss: how do you address that? i mean, this is something that i've grappled with, and i know friends of mine. i mean, i have friends who have had to basically check out and basically do therapy, who have been in nonprofits for a long time, because they get to the point where they'll have dinner with a friend, and they're like, for the amount you spent on that bottle of wine, you could have saved a life in malawi. and the friend's like, \"that's a real dickish thing to say.\"  william macaskill: yeah, yeah. i know a lot of people who've worked in nonprofits and gotten very disillusioned, very burnt out.  tim ferriss: yeah, so how do you think of addressing that?  william macaskill: yeah. and so actually, it is kind of indicative because peter singer was making these arguments since the early \u00f470s, really. and there wasn't that much uptake of them until - so toby orden, another academic at oxford, set up giving what you can. and that was in 2009. and we were saying, okay, give 10 percent. and yeah, i think there were a number of changes. so one is just we emphasize this concrete number, 10 percent. and some people go further than that. some people give 50 percent.   i'm aiming to give away most of what i own over the course of my life. so that was one thing. the second was presenting it as this amazing opportunity rather than this moral obligation, so way deeper. yeah, that's right. yeah, the way peter presents this is just, yeah, you're this asshole if you don't do this. and then people are like, well, fuck you. and that's a kind of natural human reaction, whereas actually, most people really want to do good with their lives. if you could be that person investing in that drowning child, or if you could knock down the door to a burning building and save someone from inside, you'd feel like a hero. you'd feel great about yourself. and actually, that's the situation we're in. we're in a situation where you can do a huge amount of good at little cost to yourself. maybe even, given the psychological evidence, benefiting you, because giving has a whole host of benefits to the giver as well as to the receiver. so it's actually this amazing opportunity we have.   and then secondly, i think the reason we don't give is just because a lot of psychological biases. so i remember when i was thinking about this, i just thought, i just don't want to be a sucker. everyone else is getting ahead and they're being really ambitious. i was ambitious myself. i don't want to be holding myself back by spending all this time on nonprofit stuff and giving my money away, and falling behind my peers. whereas we've built up this community effect, developed this community where everyone's kind of self-reinforcing. you get praised for doing more good or doing it more effectively. and it's this really warm, welcoming, this kind of new peer group, and part of your identity. and i think that can really help overcome a lot of the reservations that people have   and then i think the final thing is just in terms of the impact people have. so obviously, there's a huge debate about how effective aid is. and i think it's reasonable for someone who's only vaguely heard about this stuff to think, oh yeah, well, if you just donate, doesn't all the money get wasted?   because it's true. in very many cases, the money is squandered, money is wasted, and there's no impact. but then by us actually doing research and saying, no, look, if you do this, if you give money to the against malaria foundation, distribute long-lasting insecticide through the bed nets, the three-and-a-half thousand dollars, statistically speaking, you will save a life. a huge number of trials have been conducted on this to show the efficacy of bed nets. we can answer all your questions. then it's like, okay. this isn't just this kind of pascal's mugging situation where maybe i'll save a life, but i don't really know what's going on. actually, i know exactly what my money's going to go and do. and the child you save, you still will never know, but they become a little bit less faceless. it's a little bit more concrete, what you actually can achieve.  tim ferriss: did you say pascal's mugging?  william macaskill: i might have said pascal's mugging. but do you know about that thought experiment?  tim ferriss: no, i don't. i'd love to hear that, though, because that should be the title of your next book, i think.  william macaskill: okay. oh my god. i would love to write about pascal's muggingthat scenario is where it's the same as pascal's wager, except without infinite amounts of value at stake. it's not about heaven or hell.  tim ferriss: and could you just briefly explain pascal's wager for people who are not familiar, or who would like to get reacquainted, we have that as a baseline before we get to pascal's mugging?  william macaskill: i love how we've got on to this. so pascal's wager is the idea that you should go to church because you think it's incredibly unlikely that god exists. let's say you think there's just almost no chance, one in a billion chance, or something. but the payoff's just so great because it's an infinite amount of happiness. if you take a one in a billion chance multiplied by positive infinity of happiness, well, that's still plus infinity an expectation amount of happiness that you're going to get.   whereas the cost of going to church is not that great. and so if you're really kind of even just out for yourself, just looking to maximize your own happiness, then you should try and believe in god, and you should try and go to church just because the potential payoff is so great. so that's kind of his idea, this pascal idea from the 17th century. pascal's mugging is a slightly more updated version, where blaise pascal is coming out of a pub, and this kind of eerie figure approaches him and says, \"give me all the money in your wallet.\" and pascal's like, \"no.\" and the mugger says, \"well, okay, i know you're blaise pascal. i know that you think that the way to make decisions is to look at the probabilities of outcomes and their values and take that all together. and if you give me the money in your wallet, then i will come back tomorrow and give you any finite amount of happiness or money or anything you could possibly want.\"   and pascal's still like, \"no.\" and he's like, \"yeah, but look into my eyes,\" and this slightly creepy figure you don't know i'm not this alien, or someone with superhuman powers. you can't be absolutely certain of that. so you should still - by your own logic, you should still give me this money. and it's kind of a thought experiment. it goes to show that pascal would have to say, even in cases that aren't involving kind of infinities or heaven and hell; you should still do actions that seem pretty crazy to us, like giving this mugger money on this [inaudible].  tim ferriss: right. if there's a possibility of asymmetrical reward, then you should take the bet.  william macaskill: yeah, that's meant to be the argument. but it seems ridiculous, so something's gone wrong in pascal's [crosstalk].  tim ferriss: yeah. well, using that, right, everyone should invest in speculative startups, right?  william macaskill: yeah, that's right.  tim ferriss: pascal's mugging. i love it. i would love for a drunken hipster to try to mug someone with that approach in the mission. i'd be curious to see how that turns out.  william macaskill: with certain entities in the bay, it might work.  tim ferriss: yeah, it might, it might. it depends on who you catch, i guess, coming out of their juice bar or whatever william macaskill: yeah, exactly.  tim ferriss: i got us off track just a little bit. but in terms of why people don't give more, right? i think that there, we could look at the negative examples, right? so the guilting approach doesn't work very well, because like you said, it just provokes a go fuck yourself responsei think rightly so, quite frankly. i mean, i think it's a very naive and insulting way to kind of go about it, which doesn't have - for someone who's thought about things so rationally, it's surprising to me that singer takes that approach because it flies in the face of any type of negotiation research or pay for modification research.   so that's kind of funny. but if i look at, for instance, the causes that i've been involved with on some level - and i have not looked at them on givewell.org, but i've tried to do the amount of due diligence that i could with the bandwidth that i have, whether it's, say, donors choose that does a lot of work with education, or charity water, for instance. they both do a very good job of concretizing the abstract. so they send you photographs, updates, letters, etc. to make you feel like you are rescuing that drowning child in your own suit. just to come back for a second, the mosquito nets that you mentioned, is that the type of conclusion someone could come to on givewell.org, or are there other sites that they should check out? and we usually do this at the end of the show, but since we're on it, what other resources can people use, given their busy lives?   the people who have the most resources to allocate to something like this are usually also the busiest, right? and i think that's another challenge.  william macaskill: yeah, yeah.  tim ferriss: so what's the most elegant way, time-efficient way, to figure these things out for oneself?   william macaskill: yeah, so if you're busy, by far, the best thing is just givewell.org, where they just have these four top recommended charities. so they just try and find out what are the charities that are doing the most good that we know of? and those charities are against malaria foundation, which distributes bed nets, saving a life without three-and-a-half thousand dollars. the best charities often have the worst names. and so a couple are deworm the world initiative and the schistosomiasis control initiative, which when i first researched it five years ago, i could not pronounce.   and they deworm schoolchildren. so people don't really know about this, but over a billion people worldwide suffer from these parasitic worm infections in their guts. and they don't kill as many people as hiv, aids, tuberculosis, malaria, and so on, but they do just make huge numbers of people, especially kids, sick. and therefore, they don't go to school. they earn less, they're less productive later on in life. and they're incredibly cheap to treat. it only costs about 50 cents per child. and then the final charity i recommend is give directly, which simply transfers cash directly to the poorest people in the world, like the very poorest people living in kenya. and about 90 percent of the money that you give ends up in the mobile phone bank account of those extremely poor people, which they then can spend in whatever way they believe is going to most benefit themselves. it's the ultimate charity if you're really worried about white knights coming over to try and help the problems of some other country we don't really understand.   and the people who receive the money tend to spend it on assets like tin roofs and livestock. so yeah, that's the best place to donate or to look if you want just an incredibly well-researched set of recommendations.  tim ferriss: because i think that there are people listening who will have questions like those i'm going to ask, i'm going to challenge - i'm going to ask questions that i think might push in a couple of placesthe first is, are there any organizations or resources like givewell.org that are less human-centric? and the reason i ask is that the roi seems to be measured by the number of human lives saved   are there other organizations or people who have evaluated cause-driven nonprofits, ngos, whatever they might be, that are not focused on the number of human lives saved?  william macaskill: yeah. so there's one i actually helped to set up called animal charity evaluators. and that's applying the same sort of - attempting to have the same sort of level of vigor of research, but who you want to help are just animals. where should you donate? and they have a much smaller operation than givewell, but again, you can check them out for their sort of recommendations. in terms of if you're thinking about the environment, there i'm just less sure, actually. givewell is starting to broaden the research that they do, so they're working with a foundation called good ventures, which is set up by kevin turner and dustin moskovich, who's one of the facebook cofounders.   and there, they're looking into a much wider variety of causes beyond just global health and global development, including things like climate change, fundamental research, policy reform, especially immigration research and criminal justice reform, and trying to look for - comparing across all different causes you could be interested in, what are those that are particularly great in scale, so it's just a very big problem, particularly neglected. so there aren't very many other philanthropists or actors trying to solve this problem, so it's not very crowded, or particularly [inaudible], so where there's just really great programs that haven't yet been funded. but we know they're going to make a really big differenceand some of the ones they're championing are improving conditions of animals on factory farms, improving immigration policy, improving criminal justice policy to reduce the number of people who are incarcerated, while at the same time maintaining the same level or better level of public safety.   and then also, the risks of kind of global catastrophe. new technology is often climate change, or from developments in biology and so on.  tim ferriss: got it. thank you. related question or quandary, maybe, for, i think, all the people listening. so if you look at a given high need population. let's just say we're looking at - you gave kenya as an example - we're looking at kenya. the reflex seems to be to help the poorest of the poor. are there philosophers or philanthropists out there that you respect who disagree with that?    in other words, people who say, you could give $10 to the 10,000 poorest people in kenya, but i'd prefer to try to identify the, say, 200 most promising young students who could become the leaders of tomorrow, and break the cycle of poverty in this country through policy reform, and this, that, and the other thing, engineers, blablabla. but it's a much more expensive per person proposition probably, right? maybe they have to be sent to the us or cambridge or oxford for education, for instance. how are people thinking about that, and is there anyone who - it's politically safe to say, we want the focus on the poorest of the poor. no one's going to rake you over the coals publicly for that, right? but are there people who take the opposite approach, whose arguments you think have some validity, or that are interesting?  william macaskill: yeah, so i can think of a couple good arguments here. so in terms of the argument for focusing on the poorest, it's just because of diminishing marginal returns for money, and the fact that in rich countries, if you're earning above $10,000 per year, you're among the richest 15 percent, 10 percent of the world's population, even taking into account the fact that money goes further overseas. and if you're earning above $50,000 per year, then you're in the richest one percent of the world's population. and the poorest people in the world only earn about 60 cents per day, or the equivalent of what $1.50 could buy in the us. and for that reason, additional resources to them makes such a much bigger impact than additional resources to people in richer countries. in my book that just came out, doing good better, i talk about this as the 100-fold multiplier.   a dollar to me is going to do less than a hundredth of as much good as a dollar going to some of the poorest people in the world. i think there are a couple of ways in which there can be things that focus on people who are already comparatively well off, and that can do a huge amount of good. and one is through research and innovation, so increasing that. so a huge amount of good has been done in the past through developments in science and technology  and medical research. so mobile phones got developed by motorola in the \u00f470s, and now cost sub-saharan africa - the majority of people own a mobile phone. so you do get this kind of over the long-term trickle down effect as a result of research and innovation. and that tends to get underfunded by the market.    and then a second thing is if you can kind of harness these incredible resources, which are these very talented or very ambitious or more well off people, and kind of direct them in a way that's going to do more social good. so that's the approach 80,000 hours takes. my nonprofit advises on career choice. we're a small operation. we need to focus. and so we focus on those elite students, the kids coming out of ivy league schools. not because we think it's comparatively important to make harvard grads a little bit better off, but rather because they're the people that are really going to be the leaders of tomorrow, or they could be shaping the world. you want them to be doing more to improve the world, both by having more kind of motivation to do good, and using that motivation in as effective a way as possible.   and so those are a couple of ways in which i think you can do a lot of good by focusing on areas other than the very poorest of the poor at the moment.  tim ferriss: and there's an organization that i'm involved with called questbridge that people can check out if they're interested that i think is sort of along these lines. and it complements, in a way, the underserved students that i work with vis-a-vis donors choosebut reid hoffman and others are on the advisory board for questbridge, so people interested can check that out. did an  interview with reid hoffman for this podcast that discusses that on some level. if you wanted to convince people to help others, but to do it through pure self-interest, how would you go about doing that, and what would the form of giving look like?   so in other words, if you can prove to someone they will be happier if they give enough to save the life of one person per year, for instance, right? i think we're going to get into andreas a bit. i think that would go a long way to - and i know this sounds maybe cynical and terrible, but i don't think that saving a life is enough to get millions of people to donate money. it sounds terrible, but i think that appealing to self-interest is sort of the trojan horse necessary to open them to that experience. what would it look like? and i started thinking about this very specifically over the last year also because i'm involved with various cause-driven companies, both nonprofit and for-profit. and i took my family, took my parents and siblings on a trip to iceland last year.   it was the first time that we'd taken a family trip in 15 years or soand the anticipation of that was so much fun and made it so much more valuable to the entire family, all of the brainstorming and the researching and the sharing photos and so on, before it happened, that i started thinking of how that type of structure could be wrapped around something like cause-driven companies, whether nonprofit or for-profit, right? so if somebody really wanted to get - just pure self-interest. i want to improve my quality of life, my optimism, my self-reported wellbeing, blablabla, how should they do it?  william macaskill: yeah. so i think, i mean, the psychology evidence itself does suggest, actually, that giving - i mean, it suggests a couple of things. one is just that money is actually way less than important than we think to making ourselves better off   the relationship between higher levels of income and higher levels of happiness is really very low indeed, whereas other things, like having a really good community around you is actually very important. having a group of friends that really like you is very important to being better off. and so one thing is just, yeah, if you want to start doing good, especially like with the effective altruism community, suddenly you find you've got thousands of new friends who really want to support you and make you do better in life. and that's, i think, one reason why the people who have been my peers who have started giving, actually feel, including myself, just actually feel really good about this decision. another thing is just the direct effect of giving. you get a kind of warm glow. so people do tend to feel - and they've don psychology experiments on this as well, looking at people who donate rather than spending money on themselves, and people tend to feel happier.   after having donated, they feel better about themselves.  tim ferriss: is there any particular type of donation or type of cause that has the most significant impact in that respect? does that make sense? i know we don't want to do this, but if we put efficacy aside, what are the characteristics of the donation that has the most persistent effect on happiness, self-reported happiness, all of that stuff? is it the flipping through the pamphlet to choose between the goat or the chicken or the fill-in-the-blank for - the kid who's pictured in the back? is it something else? what are the characteristics of sort a selfishly fulfilling charitable giving event?   william macaskill: yeah. so i don't know if there's any research done on this, but i suspect it would be, if i'm honest, not exactly the sort of things i tend to promote. it would be things where your donation's quite public, but not in a way that comes across as sanctimonious, but just that people know you're doing a lot of good, and where you get the kind of positive feedback as a result. so probably donations within your own community, or where you can see the kind of tangible benefits of what you're doing. that's going to be a really big factor. and then i guess if you're part of a peer network where you've got a number of people kind of all doing the same thing, that's also going to be - and those people who are kind of self-reinforcing. so also saying, yeah, that's the awesome, what you're doing. you're this really good person as a result. i suspect that's also going to be one of the biggest ones in terms of increasing your level of happiness.   whereas purely, i suspect donating to someone just on the street, where you never hear from them again, that's got to be among the worst because that tends to sell you by making you feel guilty for a time, and then you donate in order to alleviate the guilt as opposed to this positive kind of ongoing thing where you get consistent feedback, whether that's from the community or the people you can actually see who you're benefiting.  tim ferriss: well, it's a negative reinforcer, right, as opposed to positive reinforcer. and if you look at dog training, or really any mammalian training, that doesn't produce a lot of enthusiasm.  william macaskill: yeah, that's exactly right. carrots work and sticks don't, at least not in the long run. and the kind of worry i have about fundraising in general is that you get this competition between charities, and you could get this race to the bottom where they hold up bigger and bigger sticks, and that means that people just end up getting annoyed or fatigued by these constant requests for donations.  tim ferriss: well, right. and we're going to talk about y combinator in a second.   but i want to make sure we come back to this because i think many people - more people would be willing to get involved with charities or nonprofits if they felt they would stop getting annoyed, or that there wouldn't be incessant follow-up with guilt, guilt, guilt, like every letter they receive. i think a lot of people don't want to open the door to that type of haranguing and kind of incessant barking, so to speak, so they never take the first stepdoes that make sense?  william macaskill: yeah, no, that's exactly right.  tim ferriss: well, let's just cover it now. if you could make a plea or a suggestion to people involved with nonprofits out there and say, stop doing this, this, and this; start doing this, this, and this, what would be on those lists?  william macaskill: yeah. i mean, one thing for sure - so i used to work as a - in the uk, we call them chuggers, or charity muggers. people who are on the street who then harass you for $10 a month. people seem to really hate that, as i know, having done it. and i think that's something that's particularly damaging. another is these pictures that you get of children in poverty with bloated stomachs and flies in their face. and it does a couple of bad things. one is just that it makes people really not want to get involved because it's these kind of horrific images that very naturally, you want to steer away from. and then also, just paints this really bleak picture, and kind of quite a disrespectful picture of people in poor countries as those who are just helpless. whereas i think if you are, like you say, doing positive reinforcement, so instead, you're like, hey. this person donated $1000 and was able to deworm two whole schools isn't that amazing?   that's much more compelling. and if you could get charities to kind of band together to have that approach, then i think you'd do a lot more good. and then i think the second thing would be in terms of the amounts asked for, i think there's also a race to the bottom in terms of different charities wanting to ask for less and less. because if you've got a choice, oh, one advert's asking me to give $10 a month; another's asking me to give $2 a month, and i've got the same feeling of gift i can resolve either way, then i'm going to donate for $2 a month. i think that's just not an appropriate reaction if the images they're showing you are of these starving children. and so again, i'd rather if we campaigned to say, the amount you should give is two percent - everyone should give two percent. and then it's up to you where you give it, but that's what you should be aiming to do. and then it's just the one-off thing, it's just this one campaign. you don't get asked all these - i mean, this is part of a classic bit of social psychology.   you want to disaggregate costs and sort of disaggregate benefits and aggregate costs. where getting asked to make a donation is a kind of cost and it can be a bit unpleasant, but then you want the benefits that come and the rewards you get to be as recurring as possible. and so having different charities saying, look, this is the standard, two percent of your income. well, maybe you could try for more, but that, i think, would be a decent amount to publicly say. then i think people could - i mean, you could make a huge difference with this. i think people could really get behind that and would start to have a more positive view of charity and trying to help others.  tim ferriss: let's segue to y combinator. so y combinator, for those people who are unfamiliar, is like the harvard all souls navy seals of startup accelerators. and they would dislike the term incubator, but a lot of people have a better familiarity with that.   people apply. very few get accepted, and there are some huge companies that have come out of it, dropbox, etc. you participated in y combinator as a nonprofit, which i think is unexpected to many people, or seems like a mismatch. can you describe how you came to apply and get accepted to y combinator? tell me the story of how that happened.  william macaskill: yeah. so the charity was 80,000 hours. that's the career advice one that went to y combinator. and we had been doing research into different career paths. and one we recommended really highly, actually, was tech entrepreneurship. and that was for a few reasons. one is because we think that early on in your careers, you should be really just trying to think about the long-term. you should think about trying to build up yourself as a person, your skills, your network, your credentials, how much you're learning.   and trying to run a startup is one of the best things you can possibly do for that, or being in the early stages of a startup as an early employee. it also has potentially great payoffs in terms of the good you can do through entrepreneurship. i can tell you about some really amazing companies that are doing incredible things to improve the world. and then also, if you do get really big, if you have founded a dropbox or an airbnb or something, then you have huge financial resources that you can use to make an absolutely massive difference, as bill gates has done. and so we were promoting that quite heavily. and that meant that when y combinator started to say, okay, we want to do nonprofits. we're going to open the doors to nonprofit applications where they'll just give a grant instead of an investment, a lot of people then contacted us. and we thought, yeah, this is just a perfect fit   we have the same sort of mentality. so the nonprofit space can be very stale, very unambitious, very unoriginal, whereas we want to be really big, and we think we can give the best advice in the world for people who want to make a difference with their careers. and we think we can reach - we want to reach everyone's who's graduating from university[inaudible] we're focused on numberswe actually are thinking in a quite similar way to a full perfect startup. y combinator seems like a really good home. so i made the application, and it's a very funny process because there's the application form and a one-minute video. so everything is incredibly condensed in terms of what the partners actually reviewan application form and a one-minute interview, a one-minute video of yourself. and we just got drunk and filmed it.  tim ferriss: what are you supposed to put in that one-minute interview - excuse me - video? you incepted me. what is the content of that one-minute video supposed to be?  william macaskill: yeah. so in that one-minute video, i mean, you can talk about anything. sometimes it's just a conversation between founders. but for us, we talked about - actually included the warm-up that we were doing. so for about 20 seconds, it was just us singing. but then talking about what exactly 80,000 hours does, what's the problem, how we're going to grow, why do we think we're a team that's good enough that we're actually going to be able to become an absolutely massive organization? that was kind of how we approached it. but the key thing is just - and this is amazing how often founders fail to do this, is just actually conveying what you do. because you get the curse of knowledge where you're so invested in this project that you've got so much detail and so much on your mind. then when you actually try and convey it to someone who isn't as familiar, then you completely bastardize it, and people have no idea what you actually do.  tim ferriss: yeah, sort of drown them in the minutiae, and they can't see the big picture.  william macaskill: yeah, exactly. and this is something that the y combinator partners were so good at - every single week, we'd just have to give the one sentence description of what we do. and for us, now it's gives career advice for people who want to make a big social impact in their lives. so just actually explaining that and explaining exactly how you do it was just absolutely the key thing.  tim ferriss: and when were you at y combinator, then?  william macaskill: so yeah. we were there summer batch, so just the last few months of the summer, basically, in july/august.  tim ferriss: july/august 2015.  william macaskill: that's exactly right.  tim ferriss: what were the most important things you learned or skills you developed at y combinator?  william macaskill: yeah. so the whole thing felt like this exhilarating learning experience, a whole new lens on how you build something to get very big.   and so a lot of great pieces of advice. one is just to focus on the product basically exclusively. you will constantly be tempted to spend your time doing things that make yourself look cool to your friends and family, but that aren't actually making a better product, and that aren't therefore helping your growth. so you'll be tempted to do [inaudible], you'll be tempted to hire a lot of people because then you can say, \"oh, well, we've got 20 people on the team.\" whereas hiring just actually takes a lot of time away from just trying to build a better product. the other thing is just picking your metric. so for us, that's the number of people - ultimately, that's just the number of people whose plans we've changed in a very significant way, and focus on growing that metric by 10 percent every week. so we'd been growing at something like - kind of doubling in size every year, and that makes us in the top one percent of charities, i think.   10 percent every week, that's 142 times over the year. it's just a totally different kind of level of ambition. and that really gives you focus. so you're ensured on doing just what's going to make your company, or in our case, charity, bigger and better every single week, and just doing whatever it takes to hit that 10 percent growth target.  tim ferriss: yeah, that's a focus on product in all of - i have about 40 angel investments now. and if you look at that sample set and pick out the biggest winners. and some of them are on paper still, but a lot of them have already have large community events. all of them ruthlessly focused on product, to the extent that if i brought them an amazing press or biz dev, business development opportunity partnership of some type, they would say, that looks great, but we're heads down on product   just not the right time. but we'll be sure to reach out in five months, six months. and it's that ability to say no to focus on product, which as you know, in this day and age, is the best approach to marketing and customer acquisition that you can take, since word travels organically if you take that approach. easily the most common denominator when you look at the homeruns in my portfoliogoing to come back to yc in a second. but you mentioned startups making a big difference. and one of the startups i'm involved with, for instance, is duolingo. and duolingo now has, i want to say 100 million plus users who are learning languages for free on duolingo. and the founders include louis van ann, who was effectively the creator of captcha and recaptcha, which was sold to google. and it's a very brilliant model.   i mean, they're pulling real content offline, or from clients who are paying to have things translated, and using the crowd to translate while simultaneously teaching them different languages, right? so ostensibly, you end up in two very interesting positions. you have hundreds of millions of people learning languages more effectively than through paid programs for free indefinitely. and then you also have the ability to generate revenue through translation and certification and other things. and then you also have the ability to rapidly translate. so you could crowdsource, say, turning wikipedia into some lesser known language in 50 hours of total time, which would be, of course, thousands or tens of thousands of hours of human time, but it would be simultaneous through this program, right? so they are, i think, going to have and are having a huge impact.   what are startups that come to mind for you, for-profit, that are having a huge impact?  william macaskill: yeah. i mean, i think that's a great example. and one of the things with for-profits is you can just get so big, and get so big so quickly, so being able to reach 100 million people is absolutely phenomenal, and quite hard to do if you're functioning as a nonprofit because you currently haven't the fan base. my favorite example of a for-profit company making a really big impact, again, set by someone in the effective altruism community who's also a y combinator alumnus, is called waive. and it makes remittances cheaper, basically. so globally, remittances, sending money from a country that you've immigrated to back to your home country, which is typically poorer, to your family there, is an absolutely huge deal. so there's about half a trillion dollars sent in remittances every single year. and compare that to overseas development aid spending, it's actually several times as great.   but if you're a kenyan in maryland, and you want to send money back to kenya, it's a real hassle. you have to go a western unionthe western union takes 10 percent. and what waive are doing is enabling you to send money mobile to mobile, so it's much easierand they also only take three percent. and they're growing phenomenally fast at the moment. they've already got thousands of users, and tens of thousands of users that are moving millions of dollars, even though they only just set this up and launched about six months ago. and the potential there, if you just do the math, if they're able to really make a significant change to the amount of money that's flowing to poorer countries in remittances, there's tens of billions of dollars every single year going from richer countries to poorer countries and kind of not getting taken by these middlemen companies. it's got an absolutely astonishing kind of opportunity to have a really big impact.  tim ferriss: so if you reflect back on your time at yc, as the kids call it, what were the most common debates that you had with other participants in yc, or with the partners?  william macaskill: yeah, that's a good question. yeah, i mean, one thing that was very common was how much time to spend on things that are going to grow your user base rather than product. so they said for advice, just always focus on the product. but then there's always going to be exceptions, and you always wonder, well, is this one of these exceptional cases? and that was just definitely a recurring issue because it's kind of hard to make the judgment call of, well, actually, we've already got this thing, and you're going to have to do some amount of distribution.   so that was really a kind of ongoing thing, as were all the - maybe a lot of the biggest debates were just - so paul graham is the founder of y combinator, and he has these essays, and paul graham is something of this kind of guru or god amongst the y combinator startup community. and he has these teachings through his essays. and then when do you deviate from the teachings of sort of -  tim ferriss: when do you violate the scripture?  william macaskill: that's exactly right. that was the ongoing thing. so similarly, another piece of advice was don't take any investment during the period of y combinator. it's just a distraction. just focus on growing, and then do all that after the demo day, which is the big presentation when you pitch to 450 investors in a big room. but then people would get approached by angel investors or vcs, and the question would be, well, actually, should we be taking this?   it looks pretty good. so again, there'd be ongoing debates about when should they violate these rules? and paul graham even acknowledges this. he says every single year, he gives the same advice to startup companies. every year, everyone ignores it. and then every year, they say later on, i really wish we'd listened to this advice. so that was kind of played out in many different ways, actually. similarly, for recruitment as well, we've got something where they say you want to have this exceptionally high bar for who you hire. and you either want to be spending all your time on the hire, because getting the best team, especially the early team, is just so vital. it's the most important thing. but if you're going to be doing it, it has to be absolutely full-time. the airbnb founders, it was six months before they hired their first employee because they wanted them to be so good. but again, there'll always be these questions of, well, we could do more if we hired someone now. is this one of those exceptional cases where we should violate that rule?   so that was the kind of theme in terms of the debates or things that were on peoples' minds.tim ferriss: yeah, that's another one where pascal's mugging will kick you in the nuts, right? because if you're like, well, there's a one percent chance that they could be the michael jordan of exactly what i need, so let me hire them. i mean, that's a kamikaze run at a ship, so you have to be very careful. where do some of your favorite philosophical frameworks have trouble in the real world?  william macaskill: um-hum. yeah, i think all over the place, probably. so i mean, a big thing is just, the real world is just so messy. so you've got this idea, okay, i just want to do the most good.   i want to help as many people as possible by as much as possiblethen actually implementing that is much harder to do, so. in the early stages, for example, of giving what we can, when we were doing the search into charity effectiveness, we made kind of certain assumptions about, say, the quality of academic evidence, where there's this body of kind of research of economists that we were really pretty happy just to trust. because we're like, look, these are the scientists. they really know what they're talking about. they're giving these numbers. we're happy to go with these numbers. and it turned out, actually, loads of researchers would be kind of crappy. we really couldn't trust them in the way that it would have been hoped for. instead, you've just got to go a lot more with very in-depth, independent investigations of the evidence yourself.   and that was something where you've got this kind of philosophical motivation, and then you make an assumption, which is that the people doing the experimental work, the empirical work, that you can just kind of trust what they're doing. turns out that's really sadly not the case. science is a lot more broken than you'd think kind of coming into it. and so that was maybe one case where we made some assumptions about how best to do good, but actually, when you have to start confronting the really messy real world, things got a lot more complicated.  tim ferriss: did you ever find - i don't what accent that was that i just threw out, but that's okay. did you ever find, when surrounded by startup founders at y combinator, that you felt demotivated in any way because you've pledged to donate everything you earn over around $36,000 per year to whatever charities you believe will be most effective?   do you find that that is ever a demotivator, the lack of that financial incentive? and i only ask because the ambitious set, the smart and ambitious set who make it into y combinator, they're not purely one-dimensional from a financial standpoint. but many of them want to build large companies to get exceptionally, exceptionally rich, among other things, right? and there are case studies of the incredible realities you can create for yourself if you win one of those lottery tickets, or if you can execute well enough to become one of those lottery tickets. what was your experience like?  william macaskill: yeah. so i think in terms of my personal motivation, it's almost the opposite, i think. since i decided, okay, i really want to use my life to make a big impact, including making this commitment to give away most of my income, that's made me way more motivated   because now it's not just kind of me on the line, it's like all these people i'm aiming to help. not all the time, because i've grown out, but sometimes it's the feeling of kind of urgency you get in like a war situation or something. you're like, whoa, this is a crisis. it's an emergency. you've got to do somethingand if i was just out for doing myself, i think i'd be much happier to have a somewhat more relaxed life. but i do feel, definitely doing y combinator, i'd feel envious of the for-profit companies in some ways. so the two ways i think it just - yeah, three ways, maybeone is just how quickly you can grow because you can get investment. so the top y combinator companies were getting three million dollars in investment two days after demo day, whereas if you're a nonprofit, then you were just having to go around soliciting donations.  we have really great donors who are just very rational, and it's not nearly as arduous for us as it is for many other nonprofits. but even still, it's just a much slower process for growing. second is in terms of the scale you can reach. i think something like only 50 charities have grown to more than 50 million dollars of revenue over the last 40 years, whereas airbnb, it's just less than 10 years,  grows to a 20 billion dollar company. many other examples of this as well. and given the kind of scale of our ambition, that's also something that makes me think, yeah, actually, that's a really pretty good model. and then, yeah, the final thing is, in terms of what sort of talent you can attract in as well. working as a nonprofit, you have the kind of - it's much harder to be able to pay competitively to try and get in those people who are just too ambitious themselves.   you've got a much smaller pool of people, those people who are much more motivated by the kind of impact they're going to haveand that's an extra difficulty as well. so it definitely made me appreciate the benefits of kind of for-profit models if you're wanting to have a really big impact.  tim ferriss: this is another question i think a lot of people wrestle with. give now or give later? and the reason i ask is that if people were to survey the philanthropists currently most famous for rationally giving and making an impact, you would find people like gates, for instance, right? but the reality of gates is that - and no offense, bill, but he was a predator who became an icon who became a philanthropist.   you would not consider him an altruist for the first few decades of his career. and so there are people - i actually had someone say to me not too long ago, mother theresa was a narcissist. bill gates, with a strike of the pen, can do 100 times more than she ever did in her lifetime. and therefore, if you have even a small likelihood of developing the sort of dynastic wealth of someone like a gates, you're better served, rather than kind of shaving off speed by donating along the way, to focus all of your efforts on building an empire that you can then use for the greater good. and no doubt, this is not the first time that you've heard this type of thinkinghow do you respond to that, or how do you contend with that type of thinking?  william macaskill: yeah, so that's such an interesting question. actually, when i'm giving talks, i often kind of judge audiences by whether this question comes up. so i think this is a good audiencebut no, so it's interesting. so i think, yeah. i mean, firstly, i think you can do, as gates did, just a huge amount of good by what i call learning to give, and i've promoted that, where you aim to do good through your ability to donate or through a private contribution of your labor. and i think it's not the right path for everybody, but i think a lot more people should consider it than currently do. in terms of when you should be donating, i think there's a few reasons on either side. so if you've got these amazing investment opportunities that are just going to really pay off, then you should definitely take them, where going to college is the clearest example. if you're the age of a teen coming out of high school, then you could just start earning money and donating it right away, but that would be a real mistake.   you should definitely get a degree, especially if you can go to a good university, just because of the impact it has for the rest of your life. and actually, in general, when we give advice at 80,000 hours, we think that people really underinvest in the long-term with their careers. because most of your hours that you're going to be spending working is going to be after the age of 30. and also, that's when you're more influential. so you're running an organization rather than turning for them. whereas a lot of people who want to do good immediately go and work at a nonprofit where they're not going to get as good training or skills, network, credentials, money as they would at other places, like the for-profit world, or sometimes further education as well. so i think a lot of the time, actually, people should be investing more than they dowhen it comes to the idea of just, okay, i'm already earning a loti'm just going to invest it all again on building up my own organization.   i'll donate at the end of my life. alarm bells ring for me a bit because a lot of people say that and then never actually follow through.  tim ferriss: oh, i'm sure, yeah.  william macaskill: and so i think minimally, you should start donating a pretty significant percentage just to get yourself in the habit of it, just so you know you're not telling yourself this lie. i think there are other thoughts as well. so donating has its own sort of compounding. it's like a sort of investment. so when someone in kenya buys a metal roof, they get this amazing return on that investment. it's like 14 percent per year or something. so if you're giving to that poor household in kenya who then buys the metal roof, that money that you give them compounds over time. you don't see it because the effects are kind of diffuse, but you've made the whole country that little bit richer in a way that compounds just in the same way as if you'd put it in a bank. on the other hand, though, you also just might really not know what the best ways of doing good are.   and so you might want to wait until you've just got better information, or you have better views, or are actually able to think about this. and i think that's maybe, with a lot of entrepreneurs, kind of what's going on. maybe you feel this yourself as well. i've got so much going on. if i really want to do a really good job of philanthropy, that takes time. and so i'm just not able to think about this. i'm going to have to punt it to a later stage. and so i do think there's a reasonable argument to be made there, but maybe the things you could do are start kind of binding yourself to the mast a little bit. maybe you can make some public commitments, make some big declarations publicly such that you know that if you back out with them, it's going to be really embarrassing. or you can take a pledge. so i'm the advisor of an organization called the founder's pledge, which provides you with a contract so you can legally bind yourself to give at least two percent of your income, or two percent of the profits that you make when you exit your company.   and i think that's again one of these things where you can say, okayto begin with, i'm just going to focus on building this thing as much as possible. i know that i've actually locked down my intentions, so i'm going to follow through on this later on.  tim ferriss: that's the founder's pledge.  william macaskill: founder's pledge, that's right.  tim ferriss: how many people have made that pledge to date? that's a contractual obligation?  william macaskill: that's a contractual obligation.  tim ferriss: who is the counterparty? who are you contractually obligated to?  william macaskill: so the way that works is you can still donate anywhere, ultimately, but it has to have an entity in the contract just for legal purposesso you donate to this organization, the founder's pledge itself, that would then redistribute the money wherever you wanted it to go  tim ferriss: i see.  william macaskill: so you don't have to make a decision about where the money goes until you're actually making the donation.  tim ferriss: they act a trustee of sorts.  william macaskill: that's right, yeah, a kind of intermediary.  tim ferriss: got it. you write, \"following your passion could be a mistake.\"  william macaskill: yeah.  tim ferriss: could you elaborate on that?  william macaskill: yeah. so when it comes to career advice, there's all these slogans that go around, the chief of which is follow your passion. and the idea is kind of like the idea of having a soulmate or somethingyou just look inside yourself and you've got this calling, and it's like, oh, i should be an artist. and then you see that calling inside yourself, and that's what you should go and do, and that's the way to be happy. and i just think this is terrible advice, and that's for a number of reasons. so one is just that most people don't have work-related passions. there was one study that found that most people who were really passionate students, they were passionate about things like arts, music, sports, things that are incredibly difficult to actually work in precisely because everyone's passionate about them, so everybody wants to pursue them.   so it's not really taking what the world needs into account. and it sets you up for kind of anxious soul-searching, or then trying to pursue this thing that just statistically speaking, you're probably not going to be successful at. but i think it also just misconstrues that nature of finding a satisfying career and satisfying job, where the biggest predictor of job satisfaction is mentally engaging workso its' the nature of the job itself. it's not got that much to do with you. well, obviously that is important to some extent. it's whether the job provides a lot of [inaudible], it gives you good feedback, allows you to exercise autonomy, contributes to the wider world. is it actually meaningful? is it actually making the world better? and also, whether it allows you to exercise a skill that you've developed. and then there's the final thing where you might think following your passion in terms of do something you're good atbut the thing is, if you're just starting out on work, you're probably just not that good at that many things that are work-related.   when i was graduating, i hadn't really done any management or fundraising or marketing or anything of the skills that actually get used day-to-day in work life. and so what you should be thinking when you're first coming out of university is you should be thinking like an experimental scientist, or investigative journalist or something. you should be thinking, well, what are my hypotheses about the things i could become good at? and then actually going into the world and then testing that, finding out, hey, maybe i could become good at coding, and that's something the world really needs at the moment. there's such a huge demand for coders. and then actually going out and trying that, because that's the final thing, is just people's preferences and passions change massively in ways that people systematically underpredict. so if you think back 10 years, what were you like 10 years ago? what were the things you were really passionate about? they're probably quite different from the things you're passionate about now.   but yet when we think in 10 year's time, we think, oh no, i'm set, i'm the same person now. and so really, what you want to be doing to begin with is building up a broad array of skills, figuring out what other things i can become good at. and that's the much better way to lead to kind of a successful and effective life.  tim ferriss: i agree on all those points. i think that there's another bullet, which is - i wrote an article years ago. i think it's just called \"the dangerous myth of the dream job.\" and i think the other issue - well, there are two issues that i'll underscore. the first is, as you said, humans are very bad at predicting what will make them happy. extremely statistically bad. there's this great book by daniel gilbert called stumbling upon happiness that goes into some depth on this.   now, that's great. a pretty depressing conclusion. how do you address it? i think the second bullet is realizing that one of the best ways to extinguish your passions sometimes, if you are using it to be synonymous with hobbies. let's say you surf on the weekendsyou wake up on a saturday and you surf every saturday. you love surfing; therefore, you think you should follow that as your passion. very different, that experience, and the purpose of that experience is very different from waking up at 6:00 every morning to take investment bankers out to surf every morning from monday to friday, right? and so i think people overestimate the persistence of their enthusiasm in that switch from optional activity, electional to obligatory.  william macaskill: yeah. and being in philosophy, i'm very familiar with this.   so i'm really lucky in terms of the position i got, but there's far more people wanting to do philosophy as a career than actually make it. and you see so many people like this, who got into it because they really love the subject, they just wanted to learnthey found it incredibly intensely satisfying. and then they find out that actually in the real world, they've got to work to do thisthey've just got to jump through a lot of hoops and do loads of networking and bureaucracy and admin, just as if they were in any other job. and it can be really dissatisfying. you can end up - it can actually be pretty tragic, where you end up hating the thing that you used to love the most above everything else.  tim ferriss: which is very common, extremely common. so you are a very effective young man, i would say.  william macaskill: thank you.  tim ferriss: you're welcome. i think it's pretty easy to objectively assess!  you've achieved many things that it would take people a lifetime to achieve, if they achieve it at all, so congratulations, first and foremostbut the question i'd love to ask is what book or books do you give the most to other people as gifts?  william macaskill: um-hum. yeah. so we talked a bit about the moral philosophythat was peter singer and derek parfit. so i'd definitely give them. but in terms of just improving your life and being more effective, there are two i'd mention. one is mindfulness, by mark williams and danny penman. and having had sam harris on the show, obviously your listeners will know about this, but mindfulness meditation's the most - i don't know   it's kind of like this magic bullet technique that kind of science has just recently cottoned on to where, in effect, you train yourself to be more in control of your thoughts and emotions by realizing that the current thoughts and emotions are not you. they don't define you. they're propaganda, and it's up to you to choose how you react to them. and our instinctive way, which is to fight with them, is actually counterproductive. instead, you want offset them with warm and welcome kind of curiosity, almost. and then that means you have the ability to deal with them as you like. and that's got the most evidence base in terms of - it basically seems to improve everything, but in particular, mood and self-control.  tim ferriss: who are the authors of this again?  william macaskill: mark williams, a professor at oxford in psychology who is the real kind of champion of -  tim ferriss: you're really part of the oxford mafia.  william macaskill: i know, i know. it's all so nepotistic.   but that was a coincidence, though. he's actually one of the few authors i went to just to say, look, this book, it's significantly improved my life. you should be very happy with what you've achieved.  tim ferriss: awesome.  william macaskill: and then danny penman, i think his name is, who is a kind of journalist, but also promoter of these ideas. and it's just a really good course for it. i like it because i'm a big science fan, so i hear something like meditation and i get a little bit freaked out. it sounds a bit hippie for me. whereas this is just - it's almost comically dull, in fact. i mean, they give these kind of guided meditations, and you're used to hearing this kind of female, high-pitched, dreamy voice, and instead, you get this broad midlands english accent saying, \"now, sit on a rug or a chair or on a bed, and close your eyes.\"   and it's really very kind of surprising when you first listen to it.  tim ferriss: it's just like the worst dad bedtime story ever, but effective nonetheless?  william macaskill: but then really good if you feel kind of intuitively a bit skeptical of that sort of thing because it's a very friendly, very kind of accessible introduction to mindfulness meditation. and it provides you with a course of eight weeks, where you do a series of guided meditations. and i did that course, and it's one of the things i think has had a really significant impact on my life.  tim ferriss: do you have a daily meditation practice now?  william macaskill: i actually don't, but i'm going to start again. i mean, i think there's two things. yeah, i think i'm going to start again just after the gym because i go the gym first thing every morning.   and then after that point, it can just be 20 minutes, breathing, where you first focus on your breath, and then extend that feeling of awareness to your whole body. i still meditate if i'm feeling stressed or anxious about something. it's a really nice kind of go-to activity that you can do to kind of put yourself - kind of reset yourself. but then also, the other thing is just it starts to affect your entire approach to life. so you will start to feel the rising panic, and you're much more in tune with your bodily reactions that then turn into thoughts. and then again, you can kind of catch those bodily reactions to begin with. again, kind of slow down your breathing, focus on the breath, and then realize that it's up to you how you want to respond.   and that can be very powerful because it means you have much more choice about your emotional reactions to things.  tim ferriss: what was the second book?  william macaskill: so the second book is the power of persuasion, by robert levineso i'm really in favor of matter skills. just these kind of general purpose skills that can improve your effectiveness in all areas of life. and just the ability to be convincing to sell ideas and to persuade other people is one of the most important of these skills, i think. i like to think of myself as taking laziness and making it into a virtue because why do something when someone else could do it? if you can make that into a virtue, then suddenly, you find you have all these volunteers helping you with this thing you're trying to create, and they turn into employees, and then they're away doing the sort of stuff that you could have instead just been slogging away on yourself for years.  tim ferriss: so the power of persuasion.  william macaskill: the power of persuasion. and i don't think it became that popular, but it's the best book on persuasion that i know of, actually.  tim ferriss: levine.  william macaskill: yeah. and it's quite a lot more in-depth than things like caldini's power of persuasion and some of the other books in that genre. it's incredibly interesting, and really lays out different principles, the keys ideas for persuading someone. like norms of reciprocity or escalating commitment. and it also just really shows how being persuasive a lot is often just about being a very nice, authoritative, genuine, honest person. so the key aspects of being persuasive are honesty and authority.   and many people, they think, oh, well, i want to become someone who can be persuasivethey then turn into these kind of sleazy secondhand car salesman types. and that's exactly the wrong thing to do. instead, it's actually about being this transparent person who really knows their stuff. and yeah, i've found that kind of fairly useful, especially as someone who is trying to - my life is about selling people on certain ideas, ideas of effective altruism.  tim ferriss: well, i think everyone's lives are about selling other people on their ideas.  william macaskill: yeah, basically. i mean, it comes up absolutely everywhere. and it's just very thorough, very in-depth, and really goes to the level of breaking down into really concrete principles. like earlier, i mentioned you want to aggregate harms and disaggregate benefits.   so it's more enjoyable for you to win $50 one day and $25 the next than it is to win $75 one day. whereas if that were a cost, then it would be - you'd prefer to just lose $75 at once rather than have two distinct losses.  tim ferriss: right.  william macaskill: so again, it goes to the level of very specific recommendationsand then also has amazing case studies of - it does go to the best stories of working with the very best salespeople in all different areas of life. and so it is the best book that i've read on that topic.  tim ferriss: i'll have to check it out. your morning ritual. you mentioned working out first thing in the morning. what does the first 60 to 90 minutes of your ideal day look like?  william macaskill: yeah. so in terms of morning routine, i think the biggest, i think maybe the single piece of productivity advice or productivity improvement i made was sleeping enough.   people's needs for sleep just varies massively from person to person. some people can just sleep four hours a night, and they're very lucky. i'm not one of those people. and coming to accept that was very important. so i aim to sleep nine hours a night. and then when i wake up, it's really about getting up and going.  tim ferriss: when do you wake up? what's your normal range?  william macaskill: yeah. typically, about 9:00 am, so not a super early riser eitherreally not much of a morning person, actually. so it's typically about 9:00 am. and then, yeah, it's just about getting up and going. so i eat things that i can hold in my hand. i really hate cereal. i hate thing where i have to spend a lot of my time. because also, the morning's my peak time in terms of my mental performance.   and so i typically eat breakfast bars, which i'm sure you're going to chastise me for for being unhealthy. but that's what i do in the morning. go to the gym, again, and that's probably the second most important piece of product of the [inaudible] advice, which is just get exercise. again, because i feel like in terms of my life and who i've come to be, almost all of it is in terms of the highest quality work i'm producing, rather than how many hours i'm producing. so the thought of, oh, i can sleep less and then produce more hours is just completely false economy. instead, it's just how can i produce the highest quality work? and for that, again, just exercising in the morning is the most important thing.  tim ferriss: what type of exercise? what does your routine look like?william macaskill: yeah. so i've suffered from fairly severe back pain over the last year and a half, so that's changed things quite a lot. and now, so my favorite exercise, which i was able to do when i was in cambridge and not here because they don't have the machine, is called jacob's ladder. do you know it?  tim ferriss: i do, yeah. maybe you could describe it for folks.  william macaskill: i'll see if i can describe it. so it's wooden bars forming a ladder around a conveyor belt. so they're constantly going down and you're constantly climbing up. so it's at about 45 degrees, so it's not vertical. if you ever decide to climb up a ladder, you get tired pretty quickly. and you're attached to the machine so that you're able to set the pace as well. so it's kind of like a treadmill, except you're just climbing up these bars. and it's great for me because it's low impact, because i can't do high impact stuff at the moment. but it's incredibly tiring. i remember when i first did it, i could do about two minutes, and then i would be completely conked out. and then i built that up over time. and it's the most - you feel like your entire body is just completely spent by the end of it.   yeah, so it's my favorite exercise.  tim ferriss: and then so how long does that workout last?  william macaskill: about an hour. if my back's bad, then i try and focus it to more like an hour and a half. but a lot of that time is spent doing physio exercises, so.  tim ferriss: how did you hurt your back?  william macaskill: yeah, i don't actually know. i think most cases of back pain actually don't have a clear problem. but i think it was bad postureso my best guess as to what was going on is anterior pelvic tilt, so where your pelvis just tilts forward too much, and you kind of stick out your belly kind of beer belly style. and so from there, the key is to really strengthen your glutes and your abs, stretch out your hip flexors and your lower back so that you're strengthening the muscles that are pulling your pelvis back and stretching out those that are pulling it forward.   and you get all these problems from sitting on that day. i would have terrible posture as well, so i've been dealing with that a lot using an ergonomic kneeling chair, experimenting with a standing desk, and in general, learning a lot about posture, because really, i think the kind of common conceptions of what good posture consists of is just completely wrong, actually. yeah, people think it's about sitting up very straight and very rigidly, whereas actually, it's more about getting the curve of your spine right. so having your hips tilted too far forward so that your lower spine makes your belly stick out, that's a very common problem. and then also having your shoulders kind of hunched forward, and then your neck and head are kind of like a duck, another very common problem. and so actually, if you want to test your posture, you can just stand against a wall, and you should only have two inches between - so just standing up straight against the wall.   you should only have two inches between your spine and the wall, and between the kind of curve of your neck and the wall. and for almost everyone who does that, they'll find, especially at the neck, there's just a much bigger gap than there should be.  tim ferriss: yeah, that's also hard if you have a horse ass like i do. a sort of kim kardashian ass. but so for the back, a couple of things that might be helpful, where do you feel the pain in your back? and this could be referral pain and not the - the sensation of pain might not be the location of the pathology. but where do you feel the pain the most?  william macaskill: yeah, so it's very lower back.  tim ferriss: very lower back. so a couple of things that you might find interesting to play with there, if it's the low back.   it would be number one, and you can check out kelly starett, maybe you've seen his stuff, mobility wod. he's been on the podcast as well. but try to get the head of your femur to seat at the back of your pelvis. so by sitting constantly, it tends to get pushed to the front of the hip capsule, and it causes all sorts of issues and soft tissue changes and whatnot. so if you look at exercises, and they're pretty easy to do, just on your hands and knees, and you lift one leg up and move your weight around as you apply it to one legbut if you were to look up sort of seating the femur in the pelvis, and kelly starett, i think that could be very helpful. and then secondly, have you considered using or used inversion tables or gravity boots so that you can -  william macaskill: no.  tim ferriss: so i've found this to just be tremendously valuable, where i'm decompressing my spine and putting myself into a state of traction.   i try to do it at least once per day. and most frequently, i will do that at night. so i'll hang from my - try this out, because i've talked about this before on the podcast, and i've had literally dozens of men specifically, but my audience is - or the people who listen to the podcast are about 80 percent male - come back and say that they've eliminated years of back pain doing this. and i'm not a doctor, of course. this isn't medical advice. but if you hang from your hands in the morning and then invert yourself at night for a short period of time - and if you can't invert, there are other options. but you could look at teeter hangups, t-e-e-t-e-rthere are different models. but teeter hangups. i use the bootsthere are risks involved with hanging upside down like batman from a bar with boots on, obviously. you could use the inversion table. i just use the boots.   and if you can't do either of those due to space constraints, travel, or whatever, there's also a device called the lynx, l-y-n-x, which allows you to put your lower back into traction on the ground. and it's very small. i have one about 15 feet from me behind my couch. and making it a habit, just as an experiment, to hang twice a day, once from your hands, and then again from your feet, if possible. and particularly for that, like illi epsoas pelvis low back complex, i think you could find - that would be a worthwhile experiment.  william macaskill: this is great. i thought i knew all of the back pain remedy tricks, but you've educated me. i'm am going to try this tomorrow.  tim ferriss: you could also, if you want to enjoy some masochism, but potentially reverse some of the soft tissue issues that you have, no doubt, in your pelvis from the sitting and the sort of kiphosis lordosis, that upper back rounding and then the anterior pelvic tilt, that sway back position, is you could find an art practitioner. i'm sure there are - i don't know if - there's probably one, at the very furthest from you - maybe it's farthest. i always screw those up - london. and art is active release technique. and they'll form their fingers into a ridge hand and dig it three or four inches into your pelvis and have you move your leg around. it's extremely uncomfortable. you might need a safety word. but that can have a tremendous effect on mobility and the gliding of adjacent tissues and things like that. so those would be worth checking out. but i don't want to make this about me spouting off. but since i know a lot of people who have suffered from low back pain - i previously suffered from low back pain, which i do not suffer from anymore.william macaskill: perfect.  tim ferriss: that would be a suggestion. and the other things is, what i've found is, standing at a standing desk all day long is very challenging, particularly if you're moving from location to location. if i ensure that i walk an hour a day, which we're really evolved to do. we've made a lot of compromises from an evolutionary standpoint to be able to walk for long distances. but that also helps to keep that hip complex functioning normally. and you're getting, at that point, sort of a high volume of low intensity stretching, which is very valuable. so that would be my two cents.  william macaskill: well, it's a big deal. i mean, so many people, it's like a plague or something, the number of people who suffer from back pain. and then it just can be completely debilitating. i've lost months of productivity as a result.  tim ferriss: so what i would - and you can speak to your pt about this, but i think that oftentimes, the reason people have low back pain and then cannot squat is because they don't squat enough in the first place. so the hanging, if you were to do that for a week, see how you feel, and then find a good olympic weightlifting coach, not power lifting coach. find a good olympic weightlifting coach who can train you to do overhead squats. and it may take a long time for you to get to the point where you can do proper overhead squats where you're not losing lower back stability. but that can be a completely game changer. i mean, i'm 38, and my hips and knees are better than they've been in probably 15 years. and i directly attribute that to regular deloading and decompressing of the spine, as well as a regular squatting practice, where i'm squatting every day, even if it's just for five repetitions with 45 pounds on the back, or in front of me, or overhead.   so that's a rather massive digression, but that's okay  william macaskill: well, you may have, yeah.  tim ferriss: let me know how it goes.  william macaskill: yeah. you may have given me months of extra work, so be happyhopefully it'll take away the pain.  tim ferriss: yeah, i hope it helps. i know how debilitating it can be. do you have any evening rituals, any evening routines for winding down?  william macaskill: yeah, i actually really don't have an evening routine. i mean, except insofar as i always take an hour or two off before going to bed because i used to work until i wanted to fall asleep. but that's just again this false economy because it means you just wake up much less energized. and again, it's just eating into peak productivity time. i travel a lot, so if i need to bet set in my sleep, then i take melatonin.   and then i focus a lot on getting high quality sleep if i can. so most important there, just completely shutting out light so that you're not waking up in the night at all. but in terms of something to decompress myself, normally just the regular things of seeing friends or reading. generally try to avoid watching tv or anything that's kind of bright unnatural light.  tim ferriss: speaking of bright unnatural light, what are you favorite documentaries or movies?  william macaskill: so i think by far, my favorite documentary maker is louie theroux. i don't know how popular he is in the us. he's a bit of a uk institution. have you heard of him before?  tim ferriss: i've heard of him, but i couldn't name any of his work.  william macaskill: okay. i mean, the most interesting is louie theroux's wild weekends. he tends to go to places in the us, to these weird subcultures.   and he does exceptionally well at becoming involved in those subcultures. so examples are neo-nazis, survivalists, the westboro baptist church, swingers. he often goes to prisons. you have porn, cosmetic surgeons, and the black power movement. and he come across so bumbling and naive that the people he's filming then completely reveal everything about their own crazy lives.  tim ferriss: and that's louie theroux, t-h-e, go ahead.  william macaskill: t-h-e-r-o-u-x. that's right. and it's incredibly powerful because you see him interacting with these neo-nazis, and they're grilling him on whether he's jewish. and he just keeps telling them he doesn't want to answer. and you see them, the parents are getting their children to bounce around a swastika as kind of morning playtime.   and you think, wow, i'm so happy i'm not one of these people, and so enlightened, because they're so mind-killed. they're so completely captured by this lone ideology. but it makes you think, wow, what mythical things do i believe just because of the people that i'm surrounded by? all these kind of cultural things. because they're just completely convinced of this worldview. or people who are looking for ufos all day, or people who are certain that the government is going to come and crack down, or the westboro baptist church that thinks that literally everyone is going to hell apart from them. and it makes you think, yeah, well, maybe there are things i believe myself that are just - in the future, will be looked back upon as crazy as i'm looking at these communities and thinking they're crazy.  tim ferriss: oh, i think that's no maybe at all. i think it's 100 percent certain.   i mean, i think everybody should take the approach of good doctors, or i should say the sort of perspective of good doctors, which is 50 percent of what we know is wrong. we just don't know which 50 percent.  william macaskill: yeah, that's exactly right. and i think most people don't tend to act that way. much too accepting of the status quo.  tim ferriss: oh yeah. and it's just like the quote that i always use and no doubt should implement more in my own life, although i try quite hard, is \"when you find yourself on the side of the majority, it's time to pause and reflect.\" that's mark twain. but some people interpret that to mean the majority of, say, the us, whatever their nationality happens to be. and i would just say, no, no, no. even the majority of your friends, if you have a narrative that you're telling yourself and it's within a peer group, even if it's 10 people, 20 people, you should really examine that. have a regular check-in.  william macaskill: and i think politics is the one that's the key, that's the biggest influence here, where - i don't know. people will identify very strongly as very left wing and very right wing, but it all strikes me as a very strange thing to do because they're this package of very different ideas that are associated with the left or associated with the right that don't have any resemblance to each other. like why on earth should your views on abortion be related to your views on an optimal taxation policy? those are completely distinct issues, yet they come in these packages. and i think it's because we're all monkeys walking around wearing suits. we want to form tribes, and then we start forming tribes based around, say, political identities. but then that means you'll just start to buy a package of views instead of just looking at each one on their own merits.  tim ferriss: oh, i think - yeah, that may be a separate conversation.   i think humans can learn a lot about themselves and their biases by reading at least one book on chimpanzee behavior. there's one in particular that's popped up a lot in my reading about animal training and evolutionary biology and whatnot, because i have a new puppy. i adopted a rescue puppy. and it's called chimpanzee politics: power and sex among apes, written by franz de wall, w-a-l-l. and this book apparently was used by, and i think he's mentioned this publicly several times, newton gingrich in amassing power and overcoming opponents in his political careerso i think the parallels are fascinating. and it's easy to convince ourselves that we are passionate about a particular position because the position has merit, whereas in reality, i think a lot of it is just a hardwired desire to fight and dominate and be right and so on, which you could trace back to chimpanzee behavior, find parallels.   and it's depressing, but i think also helpful at the same time.  william macaskill: yeah, it's a really useful lens, i think.  tim ferriss: if you could have one billboard anywhere with anything on it, what would it say?  william macaskill: that's a good question. so i think it would be outside the gates foundation, or maybe outside bill gates's house. i don't know where that is, but in seattle, where ultimately, he's going to donate a hundred billion dollars. and it would say, bill, you have talked, yeah. you have spoken about the risks and potential upside from in the long run, developments of artificial general intelligence, yet you're not doing anything about it yet. you haven't got involved.   you have the power to make a massive difference here. you should do something about it. i think that's what it would say.  tim ferriss: so artificial intelligence. generalized artificial intelligence.  william macaskill: and human level, greater than human level artificial intelligence.  tim ferriss: ah. i did not see that coming at all.  william macaskill: you did not see that coming. this is late on into the interview. it's a whole other [crosstalk].  tim ferriss: yeah, yeah. this is act three  william macaskill: yeah. there's a big debate in the media. but yeah, i think this is -!i know an oxford professor, nick boston, has written about this in a book called superintelligence.  tim ferriss: oh yeah. very, very famous book.  william macaskill: yeah, very important book, where sometimes, i think, it's very hard to predict the future. sometimes i think you have a bit of an inkling into it. you're able to make really educated guesses about what are going to be really big transformative technologies in the future.   the sort of things like development of fission. but it has a huge potential for power, and lots of huge potential for harm through using nuclear weapons. i think the case of development of artificial intelligence; it's not going to happen tomorrow. but thinking about 30 years, or 50 years, or by the end of the century, it's really likely it's going to be one of the most, or the most important development of the century when it does happen. like in the case, if we could have known about nuclear weapons or developing fission much earlier, we could have had policies in place such that we were really prepared for that. we wouldn't have maybe had a nuclear arms race. the world would have been a much better place. i think that's the situation we're potentially in with developments of artificial intelligence as well, so.  tim ferriss: okay. so i was planning on wrapping in another two minutes, but i can't let this one go. so you're hanging out with, you mentioned nick, superintelligence. you're surrounded by, or you have access to some very smart people who have thought a lot about this. it seems like you have as well. what percentage of those who are most educated about the potential implications, ramifications of ai are strongly concerned that it's summoning the demon?  william macaskill: summoning the demon. yeah. i mean, summoning the demon's quite an extreme way of putting it.  tim ferriss: well, yeah, i mean.  william macaskill: [inaudible] elon musk.  tim ferriss: right, that's elon musk, yeah.  william macaskill: mit. so it depends exactly on who the reference class is. but on some accounts, its the large majority, actually, where the media just completely distorts the debate because the media loves to distort debates.  tim ferriss: right.  william macaskill: where if you're framing it as this is a really important issue. it's not something that's going to happen tomorrow. it's something that's a long-term speculative issue. but obviously, we need to have a sensible, rational approach to this, and a proactive approach such that we're aware of what's coming and have taken precautions so that we use this new technology in a way that is going to lead to good outcomes and avoid bad outcomesthen the rate of agreement is just kind of very high indeed. if instead, you were saying something narrower, which is like, well, ai is going to happen in 20 years, and then it's going to be terminator scenario, and we're all gone for sure. that's a much smaller percentage of people.  tim ferriss: so let me rephrase my question, which is a totally different question, so i'm kind of cheating.  william macaskill: okay.  tim ferriss: but so you are in a very interesting because you've had the perspective and experience of watching behave what could be considered very rationally. in other words, they would rescue the drowning child, but they won't donate that amount of money for a similar, nearly guaranteed outcome, right? and then you have, for instance - this is more from my experience, but i've had a lot of exposure to lawyers and attorneys in the legal world over the last decade or so. and you'll find people who are genuinely, i would say, good people, who started out with very altruistic, world-improving agendas. and yet now, they are, say, defending child molesters in the catholic church.   and their job is to find holes in the depositions of these victims. i mean, it sounds fucking terrible, and it is. or their job is to help big oil companies avoid lawsuits and problematic legislation when there are violations of epa regulations, right? i mean, from my perspective, just horrific, evil shit. and they're able to rationalize doing it, right? everyone is entitled to due process, right? that's kind of the catchall brush aside that you hear. and but it's like they go from that to a point where - this is maybe a separate podcast, but i'm all fired up now. they go from being a hesitant participant in that to maybe now they're a senior partner, and they're like, oh, there's an oil spill. fantastic. can you imagine how much work we're going to have now, right?iand these are people who, outside of that compartmentalization, act in very good ways. so i guess part of my concern, or it's not a concern, but my question for you is, given how you've observed these quirks of human nature, do you think people who are the forefront of ai who have the possibility of changing the world in such a fundamental way, not only for other people, but to generate wealth that is almost beyond comprehension for themselves. do you think that drive and greed and arms race, because there are competing teams, right, trying to get to this point in many countries, where you have a generalized artificial intelligence. do you think that that competitive drive and desire to win and generate wealth, etc., will override the voice in the back of their head saying you need to figure out the safety precautions and the safety net before we get anywhere close to this technology taking off?   in the same way that you talked about the nuclear arms race, right? what's your perspective?  william macaskill: yeah. so sadly, i mean, this is just a classic tragedy of the commons, where if you're going to have multiple people trying to build the same thing, and where whoever gets there first wins, basically, just has much more power. and then some people think, oh yeah, we should be doing this more cautiously. that would slow progress, but we'd be having a greater chance of positive upside and fewer risks. and then they're just going to kind of lose the race. and yeah, sadly, i think it's not - and maybe you can even have that, even if everyone's acting altruistically, maybe they disagree slightly on how things should be done, and that's enough for them kind of not to trust each other and the absence of coordination.   and there, again, it's just not even a matter of people getting corrupted, perhaps, as you talk about the lawyers being happy about an oil spill, but just as a matter of economic incentives. and you can get these race dynamics. and that was exactly the case between the us and russia with nuclear weapons. i'm definitely not saying it's a perfect analogy at all, but there, there was the battle plan, which was a proposal after the second world war for kind of complete abandonment of all nuclear weapons, and all fission material would be kind of kept a check on by the united nations. and basically, all parties were in favor of this because it's the best outcome for everyone.   but it still wasn't able to happen because there wasn't sufficient trust between two countries. and then we get this incentive, this kind of arms race. and that's, i think, why we kind of want not just ai. other sort of risky technologies as well. the ability to develop pathogens, the ability to do gene engineering. we're on the frontier of developing many different technologies that have very large potential upsides and very large potential costs. and in each case, we want to have a coordinated approach so that we can ensure that we don't get those sort of race dynamics, i think.  tim ferriss: what existential threat to mankind worries you the most, or is most underrated? those are two different questions, but i'll make it two questions anyway.   william macaskill: yeah. so i guess until recently, i would have said - actually, yeah, okay. i have an answer for most underrated. so what is going to be the most? so the development of new pathogens. so once we start being able to build viruses and bacteria, then it will become very easy to potentially build pathogens that could kill billions of people around the entire world, or just almost everyone in the worldthat's very worrying, as is ai. those are the two big ones, i thinkin terms of most underrated, i think, are the ones we don't even know about.  tim ferriss: right.  william macaskill: predicting future technology is extremely difficult to do. everyone basically agrees with this.   and many of the developments that have happened over the last 50, 100 years would have been completely unpredictable 50 or 100 years before that. and we should expect, again, there's going to be developments that happen over the next 50, 100 years that no one's even thought of at the moment. and so i think that means - but you can still make some sort of progress on mitigating those risksbecause there are some things you can do, like greater political coordination across the world is just going to be really good across a very wide range of scenarios. having research institutes, working on the frontiers of technological development, doing horizon scanning to try and identify sort of risks like this. those are some of the things that we could be doing to try and mitigate these unknown unknowns. that's exactly the sort of thing we're going to be biased against because it's like, you're spending money doing something that you don't even know what it's going to help with?   how is that going to sell? so i suspect the biggest risks are ones we haven't even thought of.tim ferriss: right. yeah, the black swans. just a couple more questions. what advice would you give to your - you're only 28, so what advice would you give to your 20-year-old self?  william macaskill: to my 20-year-old self. yeah, let's see. the two, i think - so one is emphasizing that you have 80,000 working hours in the course of your life. it's incredibly important to work out how best to spend them. and what you're doing at the moment, 20-year-old will, is just kind of drifting and thinking, and not spending very much time thinking about this kind of macro optimization. you might be thinking about, how can i do my coursework as well as possible and micro optimization, but not really thinking about, okay, what are actually my ultimate goals in life, and how can i optimize towards them?   an analogy i use is, if you're going out for dinner, it's going to take you a couple of hours. you spend five minutes working out where to go for dinner. it seems reasonable to spend sort of five percent of your time on how to spend the remaining 95 percent. if you did that with your career, that would be 4000 hours, or two working years. and actually, i think that's a pretty legitimate thing to do, spending that length of time trying to work out how should you be spending the rest of your life.  tim ferriss: now, are those two contiguous years, or are those four years of total time divided?  william macaskill: yeah, i think four years of total time weighted towards the front of your career, i think. i think we should be spending a lot of time, and i do this. any sort of big decision i make, i spend a very large amount of time thinking about, is this the best thing that i could be doing? what other things could i be doing instead? are there ways i can change my plans?  tim ferriss: what's your process for thinking that through? do you sit down with a particular pad of paper and go through a particular set of questions?   what is the thinking process for important, big decisions?  william macaskill: yeahso i create a google doc that i share with friends, or people who i particularly respect, who then provide comments, and there will often be several different iterations of this. and there's a framework. so the [inaudible] 80,000 hours pretty much as well, where - because i'm thinking about the impact i can ultimately make. you can break that down into three components. impact you'll have - so this is for job decisions, but it actually applies quite widely.  impact you'll have on the job. so you can think about impact you'll have through your direct labor, through your ability to advocate for important causes, through your donations as well. but then also impact later on in life, where that's skills, credentials, network.   then also, how does this keep my options open? so academia is a great example of this. if you leave academia, it's very hard to come back. whereas if you go and do something before going into academia or doing a phd, it's easy to transition back in. similarly, if you go into a for-profit, then you can transition to nonprofits quite easily. much harder to do it vice versa. and then also how much you learn about yourself in the course of this work. then the third aspect is personal fit. so how uniquely good am i at doing this compared to other people? and so that's a kind of framework, basically just a big checklist. values, if i'm evaluating different sorts of large-scale pieces of work i could be doing.  tim ferriss: can people find this framework on the 80,000 hours website?  william macaskill: yes, on the 80,000 hours website, you'll get it kind of as soon as you go in. there's -  tim ferriss: what is the website?  william macaskill: so just 80000hours.org. 80,000 the number, hours.org. and then there's a career guide, and actually, we've kind of built an interactive tool to help you apply this framework in your own career decisions. it takes about 30 minutes to do, for how to choose that. and we'll also kind of recommend you ideas as you go through. because i think we don't often think about this in a very structured way at all  tim ferriss: no.  william macaskill: and it's the most important decision of our lives.  tim ferriss: i think i'm going to do that in the next 24 to 48 hours because i have a habit of just, at random moments, i'll have two glasses of wine and ask my girlfriend, \"what should i do with my life? what do you think?\" i mean, i'm playing a little bit. i mean, it's not the only way that i approach trying to make these decisions. but i haven't had a structured way of assessing impact of some of these larger options. and i think how -william macaskill: if you want any career advice as well, we do specialize in that, so i'm happy to give you a one-on-one.  tim ferriss: i appreciate it. i'm not sure if you could consider anything i've done a career, but.  william macaskill: well, that's the thing, actually. that's one of the mistakes we think people make, is thinking about careers. really, you should just be thinking about stages in your life, because very few people nowadays just do one thing and then stick at it for the rest of their life.  tim ferriss: yeah, definitely.  william macaskill: and you want to be much more flexible than that.  tim ferriss: yeah. and keeping the options open is a really interesting pointwe're going to wrap up in a minute, so we won't get into it in this particular conversation. but i spoke a lot with scott adams, the creator of dilbert, about this and how he approaches his life from what he calls a systems perspective, as opposed to a goals perspective. and the systems is always, in effect, ensuring that even if a given project or stage fails, the skills and relationships and so on that he develops in addition to the way in which he sequenced things, like you mentioned, allows him to be as good off, as well off or better off afterwards.   even if it's a strikeout on some other levels. this is the last question. what ask or request do you have of people listening? i mean, i'm going to throw it out there just to - because it addresses a pet peeve of mine. if you're a founder who claims to be building something to change the world, and if you're not able or not willing to contribute to any causes right now, then sign the founder's pledge. two percent is nothing. it's $2000 out of a million dollars. it's nothing. it's trivial. so i would just say, if that's your line, make sure you're not lying to yourself and other people. just sign the pledge. i don't see any downside to it that i can perceive. so that would be one ask of mine. but what would your ask or request be to the audience, and where can they learn more about what you're up to and find your work online, and you, for that matter?  william macaskill: great. so, key ask is go to effectivealtruism.com. and you can sign up for the effective altruism newsletter there. there's also, if you're interested, you can buy my book on there as well, doing good better, that's all about the ideas we talked about. at least some of the ideas we talked about, about doing the most goodbeyond that, if you want to do good with charities, see giveworld.org for top recommended charitiesif you want to do good for your career choice, 80000hours.org. again, sign up for the newsletter. and if you're really feeling inspired and you want to make an even bigger commitment than that founder's pledge, giving what we can is a pledge of 10 percent or more. and you can join the community, and it's a really kind of worthwhile thing to do that will make your life more meaningful and also have a huge impact at the same time.   but the key of those is effectivealtruism.com.  tim ferriss: and will, how do you pronounce your last name correctly?  william macaskill: macaskill.  tim ferriss: okay. and so for people who are going to misspell this, if you wanted to say hi to will on twitter, it's @willmacaskill, m-a-c-a-s-k-i-l-l. so kind of like mac a skill, i guess, if you wanted to try to split those up. but will macaskill. and then facebook is facebook.com/wdcrouch. that's a whole separate question that i want to get into. and then linkedin and so on. and for everybody listening, of course, the links that we discussed, the links that will just mentioned, those will all be in the show notes. the books, the movies, the wild weekends with louie theroux will all be found at fourhourworkweek.com, spell it all outfourhourworkweek.com/podcast. and will, this has been great fun. i really appreciate you taking the time.  william macaskill: yeah, i've really enjoyed it. thank you.  tim ferriss: thanks. and everybody listening, thank you for listening. and until next time, please experiment often, consider the impact of what you're doing. don't misspend your 80,000 hours. and check it out, 80000hours.org and everything else that will mentionedthanks so much.   hey guys, this is tim again. just a few more things before you take off. number one, this is five bullet friday. do you want to get a short email from me? would you enjoy getting a short email from me every friday that provides a little more sort of fun before the weekend? five bullet friday is a very short email where i share the coolest things i've found, or that i've been pondering over the week. that could include favorite new albums that i've discovered, it could include gizmos and gadgets and all sorts of weird shit that i've somehow dug up in the world of the esoteric, as i do   it could include favorite articles that i've read and that i've shared with my close friends, for instance. and it's very short. it's just a little tiny byte of goodness before you head off for the weekendso if you want to receive that, check it out. just go to fourhourworkweek.com. that's fourhourworkweek.com, all spelled out, and just drop in your email, and you will get the very next one. and if you sign up, i hope you enjoy it.", "speakers": ["will macaskill", "tim ferriss"], "text_sentences": ["hello, ladies and germs, this is tim ferriss, and welcome to another episode of the tim ferriss show", "i am looking out over a highway from a hotel next to jfk because i forgot my passport in california and missed my flight", "in any case, on this show, it is always my job to try to deconstruct world-class performers and identify the routines, the habits, the decisions that help them to become who they are", "in this episode, we have a really fun guest, will macaskill", "will macaskill is an associate professor in philosophy at lincoln college, which is at oxford", "he is 28 years old, which makes him likely the youngest associate, in other words, tenured professor of philosophy in the world", "he is co-founder of the effective altruism movement, which i'm a huge supporter of, and author of doing good better", "he has pledged to donate everything he earns over 36k, roughly per year, to whatever charities he believes will be most effective", "he has cofounded two well-known nonprofits, 80,000 hours and giving what we canand we'll get into both of those", "but more important, we will talk about the lessons he's learned, how to evaluate doing good, how to hack doing good, as you would in business", "and he has been exposed to business", "he is one of the few nonprofit founders who have gone through y combinator, which is effectively the harvard navy seal equivalent for startup incubators based in silicon valley", "and his stories are just fascinating", "we talk about many different things", "we cover a lot of ground, everything from artificial intelligence to why following your passion in a career is often a mistake; how on earth he became a tenured professor at his young age; thought experiments, like pascal's wager versus pascal's mugging", "and even if you have no interest in nonprofits or charities, this will help teach you how to think more effectively, how to evaluate things more effectively", "we'll also talk about some specifics, why donating to disaster relief or purchasing things through ethical consumerism are generally not a great way to do good", "but we talk about his story, his decisions, and there's a lot to be learned", "so say hello to him on the interwebs", "will is @willmacaskill, @w-i-l-l-m-a-c-a-s-k-i-l-l on twitterand please enjoy our conversation", "thanks for listening", "will, welcome to the show", "william macaskill: thank you for having me on", "i really appreciate you making the time", "and where do we find you on the planet earth at this moment", "william macaskill: i'm at oxford in the united kingdom at the moment", "and now, you are an associate professor in philosophy at lincoln college, is that right", "william macaskill: yeah, lincoln college, oxford university", "and lincoln college, it's not a residential college", "so for instance, at princeton, they have different residential colleges", "what is the significance of the colleges within oxford", "william macaskill: yeah, it's a really big thing, actually", "so almost all your teaching goes on in college, you live there, you eat there, most of your friends are there while you're a student of the university   and actually, all the colleges predate the universities", "so that's really the core of your life at oxford", "and then you get examined and go to lectures at the university itself", "and when you'd receive a degree, is it from a particular college", "do you have to attribute it to the college or it simply oxford", "william macaskill: no, the degree's just from university", "got it", "so let's, then, begin", "you do quite a few things", "when someone asks you what do you do, how do you answer that question", "william macaskill: that's right", "so depending on whether i want to be low-key or not, i'll tell them i'm an associate professor of philosophy at oxford university", "i'm also one of the cofounders of the effective altruism movement, where that's a community of people who are dedicated to using their time and money as effectively as possible to make the world a better place", "and to that end, i cofounded a couple of nonprofits", "giving what we can, which encourages people to give at least 10 percent of their incomes to the most effective charities; and 80,000 hours, named after the number of hours you typically work in your life, which is about giving advice to people to ensure that if they want to pursue a career with a big impact, they can do as much good as they can", "and how do you answer the question, what makes your brand of altruism effective", "and maybe we can back into that with - there was a tweet i saw at one point from bill gates, and it was \"a data nerd after my own heart,\" and he linked to an article about you", "i think it was a profile in the atlantic", "william macaskill: that's [inaudible]", "so if you're talking to a skeptic and they say, okay, well, what makes it effective", "william macaskill: okay, yeah", "so the key is that we take a scientific approach to doing well", "so that's using high quality evidence, really good data, thinking about the outcomes that your outcomes do rather than just what's a really sexy intervention, or what makes you feel good, but actually what's helping people the most", "and going on years of research now, as well as using careful, reflective, self-critical reasoning in order to work out what those things aren't just making a difference, but are making the most difference", "and what are some common mistakes - and just so people listening understand this, this isn't a disguised sell for nonprofit donations on my part", "this is a conversation that i've wanted to have with you because we have a mutual friend in ryan holliday, who is himself a philosopher of sorts, huge fan of stoic philosophy, as am i", "and he is a fan of yours", "and i was very interested to connect", "so just for those people who were wondering if this is a dressed up sales pitch, it is not", "what are common mistakes that people make when giving", "and i've had many of my own struggles with providing time and money to various causes and nonprofits", "maybe we'll dig into some of them specificallybut what are some common mistakes or misallocation of resources that you see very commonly", "william macaskill: so yeah", "i think the biggest mistake of all is just not really thinking or doing any research at where you're donating   so i mean, imagine if someone came up to you in the street and told you about this company that they'd set up, or that they were representing, and that you should really invest in this company, and they tell you about how great the company is, and then ask you right there on the street, \"well, are you going to make an investment?\"isounds like silicon valley right now", "william macaskill: well, that may be a little bit different, but", "certainly, here in oxford, people would be -  generally not a good idea", "william macaskill: yeah, generally not a good idea", "but yet, we're happy to do that when it comes to charities", "we're happy to spend our money to try and help others, but without ever actually doing the research to work out what is going to actually have the biggest impact", "and there are evaluators now, like giveworld.org, that are doing this research for us so that we can actually follow their recommendations, because it does take quite a bit of time", "how is giveworld.org compared to, say, charity navigator or something like that", "william macaskill: yeah", "the really big difference is charity navigator focuses just on kind of the financials and just on the aspects of a charity itself, where one core part of it is how much does the charity spend on overheads", "what's the percentage spent on administration", "but that's not a great metric because imagine you've got some really lousy program", "you're giving away donuts to hungry police officers or something", "something that's not going to do very much good", "but you've got this amazingly low overhead", "you're spending almost nothing on administration", "well, you're still going to be a lousy charity", "you can't make a lousy charity good by having a very low overhead", "right, got it", "william macaskill: yeah", "you're looking at these sorts of operational efficiencies, but whether something is efficient or not, it can still be very ineffective", "william macaskill: yeah, that's exactly right", "so you've got to look at what program the charity's implementing as well", "and there, there are absolutely huge differences", "so three-quarters of social programs, when put to the test using trials, are found to have no effect at all", "they just don't actually improve peoples' lives", "some are even actively harmful", "but then among the ones that are good that do make a difference, there's still a vast disconnect", "the best ones are hundreds of times as good as merely ones that just do some amount of good", "and it seems like you are a skeptic of disaster relief", "is that a fair statement", "or how would you unpack that", "william macaskill: yeah", "so i mean, i think funding disaster relief, it should happen for sure", "when there's a massive crisis like the haitian earthquake, money should be going to it, and a lot of money, in fact", "but then the question is, what should you as an individual donor do", "and natural disasters, because they get press coverage and so much media attention, they're massively overfunded compared to what i'd call ongoing natural disasters like the 400,000 people who die of malaria every year", "but it gets far less media coverage", "and in fact, even in the case of the japanese earthquake, the japanese red cross issued a statement saying, \"we do not want any money", "we do not want money", "we're the fourth richest country in the worldwe have resources to deal with this problem.\"   but yet they still got five billion dollars in donations, which is about the same as got allocated to haiti, which is one of the poorest countries in the world", "understood", "and let's take a step back from it because i know we could really dig into the sort of tactics and science and numbers behind what you do", "but you are currently 28, is that right", "william macaskill: that's right", "and you are a tenured professor of philosophy", "william macaskill: yeah", "where does that put you on the spectrum of tenured professors of philosophy worldwide, age-wise", "william macaskill: age-wise, it's hard to verify, but i suspect i might be the youngest in the world", "and to what do you attribute that", "why you", "it's a very competitive field, as i understand it, the philosophy", "i want to ask a question about this", "philosophy post-grads have the highest gre scores out of any subject", "so what are the factors that contributed to you becoming tenured at such a young age", "william macaskill: yeah", "so i definitely think it's not because i'm the smartest personi'm very confident i'm not", "i know lots of people who are, like have exceptionally high iqs around these places", "and also not, i think, because i put in the most number of hours, because i do so much other stuff as well", "but i think the two things that just - one is actually kind of understanding, really thinking about what your goals are, and understanding how is it best to achieve those goalswhich seems like it's a bit of common sense", "you'd think everyone would do that", "but actually, most people don't", "most people spend, for example, years and years kind of slogging away just on their dissertation, on their phd, even though that's normally read by four people in the world, rather than focusing, say, on publishing really good articles, which are read by much more people and much more important in terms of doing well in their career", "and then the second aspect is just absolutely a ruthless application of the 80/20 rule, which obviously, you talk about in your bookbut just the idea that of the stuff that you do, most people do, almost all value comes in a very small number of activities", "and again, i think a lot of people in academia get a lot of their time used up with busy work, so attend conferences, go to seminars, they do a lot of reading, that doesn't ultimately contribute to what they're really trying to do, which is come up with new ideas, new arguments, and really put that forward", "and so, i think i have been just a lot more proactive and kind of goal-oriented in terms of the approach i take to my work", "so let's get into detail with that because i know people love the details", "and not surprisingly, a lot of people listening love the 80/20 principle or all applications of that", "if we rewind to your undergraduate, were you studying philosophy in undergrad", "william macaskill: yeah, that's right", "i was at cambridge university as an undergrad", "and what did the trajectory look like", "what were the inflection points or key moments between that point and getting tenured", "william macaskill: yeah", "so i think i was a lot less effective as an undergrad", "i was still trying to discover how to do things effectively, and i made some big mistakes", "and i remember trying to train myself to only sleep four hours a night, and that was a disaster", "that was the worst year of my life", "then i realized, no, actually, sleeping well and exercising well are really important in terms of having good performance", "one thing i realized as an undergrad was just that you can just make so much progress just by finding someone smarter than you and learning from them", "and that's exactly what i did", "someone who's now a close friend of mine just knew absolutely everything, and so i'd spend just hours talking to them", "who is this", "william macaskill: so he's andreas morgenson", "he also got a professorship at oxford", "uh-huh", "in the philosophy department", "william macaskill: in the philosophy department, that's right", "so we've ended up having a very similar career trajectory", "and i've been a zombie and eaten his brains every stage of the way", "but then in terms of the big inflection points, i think really came - it was only when i moved to oxford to do my postgrad work that i started to get a lot more serious about this", "also realizing getting funding to do philosophy postgrad is pretty hard, and realizing that there a lot of lot scholarships out there that most people have never heard of, and they actually don't therefore get that many applicants, so if you apply for them, you can actually have a bigger chance", "and then i managed to get funding for my phd and extend it by a little bit more than other people do through a combination of, i think, eight different scholarships in the end", "and so doing that", "and then the big thing was just from the outset, i was starting a phd thinking, okay, well, philosophy's incredibly competitive", "if i do want to do this as a career, then i've really got to know what's actually expected of you, like on what basis you can get hired as a professor", "and the answer is weirdly disconnected from what you typically do as a grad student", "at least in philosophy, people basically judge you on the quality of your best five or 10,000 words of work, whereas your dissertation is kind of 80,000 words or something", "and so if you want to really do well, then it's just about making that highest quality stuff as good as possible, and in trying to get it published in the very best journals", "so it's really about optimizing for your kind of peak output, rather than just being this kind of big generalist", "got it", "what was your dissertation on", "and what was your best five to 10,000 words about", "william macaskill: oh", "so my dissertation was about ethical uncertainty", "so if you're unsure about what you ought to do", "so maybe you think, okay, well, i think it's okay to eat meat, but i'm unsure about that", "there are all these vegetarians around and they have these arguments and so on", "and you're like, well, i don't quite know what to do", "how should you act in light of that", "how should you take uncertainty into account", "and this was quite a strategic choice of topic as well because it's a very important topic, but almost nothing has been written about it", "so i could read everything that had been written on it in about two weeks, whereas many people choose to pursue phds on something that's already had a huge amount of work done", "and so that was what the phd was on", "and in particular, i argued that even if you're unsure about your values, you should treat that uncertainty in the same way as if you're unsure about matters of fact, or what's going to happen", "so in the same way as if you wouldn't speed down a blind corner if there's some risk of a child playing in the street, even if you thought there was probably no one there, you still wouldn't want to risk it", "in the same way, if you think, well, maybe something's wrong", "i think it probably isn't, but there's a risk, and if it was, it would be very wrong", "i think you should take that same course of action", "you should again kind of play safe, as it were", "sort of pascal's wager for life", "william macaskill: it's a little bit, yeah", "it doesn't involve infinite amounts of value, though that's interesting too", "but a little bit like pascal's wager for life", "and then what about your peak or your best five to 10,000 words", "was it the same subject, or something completely different", "william macaskill: yeah, so it was the same subject as well", "and this is all quite distinct from my effective altruism stuff", "but it was the same subject, and in particular, i saw there was this analogy between that sort of decision and a bunch of work that had been done in economics", "so again, this is something where you can make a progress by doing research, just by combining two different fields", "because the number, the combinations of fields are just far, far greater than the number of fields themselves", "and so i argued that this problem was kind of like the problem of voting", "so in just the same way as this problem of if you put all these people with different preferences, and you kind of aggregate that into one social preference, or one just will of the people, as it were", "and there's just a ton of that done in economics that's really interesting and often quite technical", "and i said that was kind of the same as a decision under ethical uncertainty", "it's like you've got all these different ethical viewpoints, and they're like different voters", "and if you want to be able to make a decision between them, in light of that kind of uncertainty, you can treat them as like voters", "and you can use all the same technical apparatus that have been developed in economics and apply it to that case of ethical uncertainty", "so you mentioned andreas morgenson", "what other philosophers are your - idols is a strong word, but role models", "people you really look up to you", "alive or dead", "if you have to put sort of your top five or fewer philosophers on a list, who would they be", "william macaskill: yeah", "so there are two who really stand out", "the first one, more of kind of an academic, is derek parfit", "how do you - derek parfit", "william macaskill: parfit, yeah", "p-a-r-f-i-t", "and he's spent his entire life at all souls college in oxford, which is elite, even within oxford", "what was the name of the college", "william macaskill: all souls college", "all souls", "william macaskill: all souls, yeah", "the way you get into all souls college - and andreas achieved this as well - is you have to sit 15 hours of exams", "and you have to answer questions that can be on any topic, like is china overrated", "why democracy", "how many people should there be", "and then the final three-hour exam is just on a single word", "that sounds horrible", "sounds very uniquely philosophical, too, i mean, in terms of academia", "william macaskill: it's crazy", "it's sort of known as the hardest exam in the world", "but it gives you seven years of funding, and you can do whatever you want in those seven years", "what's the name of the exam", "william macaskill: it's called the all souls prize fellowship, i think  ah, okay", "so derek is one", "william macaskill: he is one, and he's now 70", "and he wrote a book called reasons and persons, which i think is one of the most important books written in the 20th century", "could you say that one more time", "william macaskill: reasons and persons", "reasons and persons", "william macaskill: yeah", "and it argues, oh, a whole number of things", "but two of the big things are - one is the idea that there isn't really a continuing self over time", "so there's nothing kind of fundamentally distinct between will macaskill, age 28, and will macaskill, age 70, versus will macaskill, age 28, and tim ferriss right now", "there's only a kind of matter of degree between those things", "and that has a whole number of implications", "and actually, interestingly, it's actually quite similar to a big [inaudible] in buddhist thought", "and apparently, his book has been used as a text in certain buddhist temples", "they chant to it", "he didn't realize this for like 30 years or something", "and then he showed up, and there was some effigy to derek parfit sitting on a throne in a cave in tibet", "william macaskill: yeah, i think you're right", "well, i mean, it does resonate, certainly, with certain discussions of self, right", "whether it's a contemporary like sam harris, who has a phd in neuroscience, but also a very experienced meditator who wrote waking up, or texts that are thousands of years old", "i mean, the concept of a static self is something that's challenged a lot in buddhist thought, among others", "so you have derek", "who's your number two", "william macaskill: number two then has to be peter singer", "i was going to ask you about him, yeah", "william macaskill: yeah, he's a big influence, both in terms of my thought and in terms of how i'm approaching my life, the decisions i'm making, in terms of my own career", "and he has two very big, important arguments", "one is for the model importance of non-human animals, and treating them much better than we do at the momentand also the importance of fighting global poverty, especially for us in rich countries using - he really argued it should be most of your income, donating that away to charities that will help improve lives or save lives among the poorest people in the world", "he argues that if you were walking past a shallow pond and a child was drowning in that pond, and you could run in and save the child and it would ruin your expensive suit that you were wearing, it would cost you a couple of thousand dollars a result, you'd obviously go and do that", "you'd be, in technical terms, an asshole if you didn't", "he doesn't say that", "that's my interpretation of the argument", "but if so, then what's the difference between that and the life that you can save in malawi right now by distributing insecticide and bed nets to save a child from malaria", "and he argues there isn't a difference", "and he was immensely influentialhe sold millions of books and caused a large number of people to really change their lives, including myself", "so i am a peter singer fan, and i think that most people who are not, most people who protest against or picket against peter singer haven't read his work", "and certainly, he has controversial stancesbut i remember when he came to princeton to teach, and there were people picketing and rolling out their disabled children and so on because they were, i think, adopting bastardized versions of what he had said from media", "so as much as i like peter, i would propose - but you know what", "this isn't about me", "let me ask you", "do you think it's really the same insomuch as walking in with a suit and rescuing a drowning child versus saving a potentially sort of faceless child across the world, of which there are potentially millions, right", "and the reason i bring it up is not to say that people shouldn't do it, but i had a conversation with - well, actually, i suppose it was a q&a of sorts with sam harris about the - i think it's called the trolley scenario, but i'm not sure", "william macaskill: oh, yeah", "do you know what i'm talking about, right", "so those people that are not familiar with this, the hypothetical thought exercise which is going to have a lot of real implications when we're using autonomous vehicles and programming ai and so on", "so philosophy's suddenly a lot more relevant, or some of these thought exercises are more relevant than they maybe would have been imagined to become", "please correct me if i'm wrong, and i think i'm just paraphrasing this, but if you had a railroad track, and you could flip a switch for it to go down one track that was split to the left, and another that was split to the right", "there's one kind of fat man on the left, and there are four people on the right, and you have to throw the switch", "do you throw the switch to the one person or the four", "and people say, of course, that they would switch it to the one", "but then the second scenario i think of, and there may be more, is if you had to push the fat man off of a bridge so he landed on the track and was an obstacle that then prevented four people from dying, would you do it", "and all of a sudden, the percentages change very dramatically, right", "and even though the utilitarian philosophical outcome is on paper the same, right", "and i know i'm kind of brain vomiting at you, but this is something i've really grappled with", "so peter singer had a cover story", "i believe it was the new york times magazine, sunday edition", "huge piece on basically redistributing wealth for greater good", "and yet, i couldn't necessarily point to a huge change in donation behavior after that article", "so why don't more people donate, right", "because if i looked at my 10 friends, a given 10 friends who i'd consider good human beings, who have money, they would save the drowning child, but they're not going to send - if for the same reason that i think they're afraid of opening the floodgates", "if they donate to one child, does it not then follow they should donate all of the money that they have to save not one child, but as many as they can afford to save", "and they get themselves into a very hairy position where they feel like they can't enjoy the fruit of their labor because of the guilt that they feel", "does that make sense", "william macaskill: yeah, so -  how do you address that", "i mean, this is something that i've grappled with, and i know friends of mine", "i mean, i have friends who have had to basically check out and basically do therapy, who have been in nonprofits for a long time, because they get to the point where they'll have dinner with a friend, and they're like, for the amount you spent on that bottle of wine, you could have saved a life in malawi", "and the friend's like, \"that's a real dickish thing to say.\"  william macaskill: yeah, yeah", "i know a lot of people who've worked in nonprofits and gotten very disillusioned, very burnt out", "yeah, so how do you think of addressing that", "william macaskill: yeah", "and so actually, it is kind of indicative because peter singer was making these arguments since the early \u00f470s, really", "and there wasn't that much uptake of them until - so toby orden, another academic at oxford, set up giving what you can", "and that was in 2009", "and we were saying, okay, give 10 percent", "and yeah, i think there were a number of changes", "so one is just we emphasize this concrete number, 10 percent", "and some people go further than that", "some people give 50 percent", "i'm aiming to give away most of what i own over the course of my life", "so that was one thing", "the second was presenting it as this amazing opportunity rather than this moral obligation, so way deeper", "yeah, that's right", "yeah, the way peter presents this is just, yeah, you're this asshole if you don't do this", "and then people are like, well, fuck you", "and that's a kind of natural human reaction, whereas actually, most people really want to do good with their lives", "if you could be that person investing in that drowning child, or if you could knock down the door to a burning building and save someone from inside, you'd feel like a hero", "you'd feel great about yourself", "and actually, that's the situation we're in", "we're in a situation where you can do a huge amount of good at little cost to yourself", "maybe even, given the psychological evidence, benefiting you, because giving has a whole host of benefits to the giver as well as to the receiver", "so it's actually this amazing opportunity we have", "and then secondly, i think the reason we don't give is just because a lot of psychological biases", "so i remember when i was thinking about this, i just thought, i just don't want to be a sucker", "everyone else is getting ahead and they're being really ambitious", "i was ambitious myself", "i don't want to be holding myself back by spending all this time on nonprofit stuff and giving my money away, and falling behind my peers", "whereas we've built up this community effect, developed this community where everyone's kind of self-reinforcing", "you get praised for doing more good or doing it more effectively", "and it's this really warm, welcoming, this kind of new peer group, and part of your identity", "and i think that can really help overcome a lot of the reservations that people have   and then i think the final thing is just in terms of the impact people have", "so obviously, there's a huge debate about how effective aid is", "and i think it's reasonable for someone who's only vaguely heard about this stuff to think, oh yeah, well, if you just donate, doesn't all the money get wasted", "because it's true", "in very many cases, the money is squandered, money is wasted, and there's no impact", "but then by us actually doing research and saying, no, look, if you do this, if you give money to the against malaria foundation, distribute long-lasting insecticide through the bed nets, the three-and-a-half thousand dollars, statistically speaking, you will save a life", "a huge number of trials have been conducted on this to show the efficacy of bed nets", "we can answer all your questions", "then it's like, okay", "this isn't just this kind of pascal's mugging situation where maybe i'll save a life, but i don't really know what's going on", "actually, i know exactly what my money's going to go and do", "and the child you save, you still will never know, but they become a little bit less faceless", "it's a little bit more concrete, what you actually can achieve", "did you say pascal's mugging", "william macaskill: i might have said pascal's mugging", "but do you know about that thought experiment", "no, i don't", "i'd love to hear that, though, because that should be the title of your next book, i think", "william macaskill: okay", "oh my god", "i would love to write about pascal's muggingthat scenario is where it's the same as pascal's wager, except without infinite amounts of value at stake", "it's not about heaven or hell", "and could you just briefly explain pascal's wager for people who are not familiar, or who would like to get reacquainted, we have that as a baseline before we get to pascal's mugging", "william macaskill: i love how we've got on to this", "so pascal's wager is the idea that you should go to church because you think it's incredibly unlikely that god exists", "let's say you think there's just almost no chance, one in a billion chance, or something", "but the payoff's just so great because it's an infinite amount of happiness", "if you take a one in a billion chance multiplied by positive infinity of happiness, well, that's still plus infinity an expectation amount of happiness that you're going to get", "whereas the cost of going to church is not that great", "and so if you're really kind of even just out for yourself, just looking to maximize your own happiness, then you should try and believe in god, and you should try and go to church just because the potential payoff is so great", "so that's kind of his idea, this pascal idea from the 17th century", "pascal's mugging is a slightly more updated version, where blaise pascal is coming out of a pub, and this kind of eerie figure approaches him and says, \"give me all the money in your wallet.\" and pascal's like, \"no.\" and the mugger says, \"well, okay, i know you're blaise pascal", "i know that you think that the way to make decisions is to look at the probabilities of outcomes and their values and take that all together", "and if you give me the money in your wallet, then i will come back tomorrow and give you any finite amount of happiness or money or anything you could possibly want.\"   and pascal's still like, \"no.\" and he's like, \"yeah, but look into my eyes,\" and this slightly creepy figure you don't know i'm not this alien, or someone with superhuman powers", "you can't be absolutely certain of that", "so you should still - by your own logic, you should still give me this money", "and it's kind of a thought experiment", "it goes to show that pascal would have to say, even in cases that aren't involving kind of infinities or heaven and hell; you should still do actions that seem pretty crazy to us, like giving this mugger money on this [inaudible]", "right", "if there's a possibility of asymmetrical reward, then you should take the bet", "william macaskill: yeah, that's meant to be the argument", "but it seems ridiculous, so something's gone wrong in pascal's [crosstalk]", "yeah", "well, using that, right, everyone should invest in speculative startups, right", "william macaskill: yeah, that's right", "pascal's mugging", "i love it", "i would love for a drunken hipster to try to mug someone with that approach in the mission", "i'd be curious to see how that turns out", "william macaskill: with certain entities in the bay, it might work", "yeah, it might, it might", "it depends on who you catch, i guess, coming out of their juice bar or whatever william macaskill: yeah, exactly", "i got us off track just a little bit", "but in terms of why people don't give more, right", "i think that there, we could look at the negative examples, right", "so the guilting approach doesn't work very well, because like you said, it just provokes a go fuck yourself responsei think rightly so, quite frankly", "i mean, i think it's a very naive and insulting way to kind of go about it, which doesn't have - for someone who's thought about things so rationally, it's surprising to me that singer takes that approach because it flies in the face of any type of negotiation research or pay for modification research", "so that's kind of funny", "but if i look at, for instance, the causes that i've been involved with on some level - and i have not looked at them on givewell.org, but i've tried to do the amount of due diligence that i could with the bandwidth that i have, whether it's, say, donors choose that does a lot of work with education, or charity water, for instance", "they both do a very good job of concretizing the abstract", "so they send you photographs, updates, letters, etc", "to make you feel like you are rescuing that drowning child in your own suit", "just to come back for a second, the mosquito nets that you mentioned, is that the type of conclusion someone could come to on givewell.org, or are there other sites that they should check out", "and we usually do this at the end of the show, but since we're on it, what other resources can people use, given their busy lives", "the people who have the most resources to allocate to something like this are usually also the busiest, right", "and i think that's another challenge", "william macaskill: yeah, yeah", "so what's the most elegant way, time-efficient way, to figure these things out for oneself", "william macaskill: yeah, so if you're busy, by far, the best thing is just givewell.org, where they just have these four top recommended charities", "so they just try and find out what are the charities that are doing the most good that we know of", "and those charities are against malaria foundation, which distributes bed nets, saving a life without three-and-a-half thousand dollars", "the best charities often have the worst names", "and so a couple are deworm the world initiative and the schistosomiasis control initiative, which when i first researched it five years ago, i could not pronounce", "and they deworm schoolchildren", "so people don't really know about this, but over a billion people worldwide suffer from these parasitic worm infections in their guts", "and they don't kill as many people as hiv, aids, tuberculosis, malaria, and so on, but they do just make huge numbers of people, especially kids, sick", "and therefore, they don't go to school", "they earn less, they're less productive later on in life", "and they're incredibly cheap to treat", "it only costs about 50 cents per child", "and then the final charity i recommend is give directly, which simply transfers cash directly to the poorest people in the world, like the very poorest people living in kenya", "and about 90 percent of the money that you give ends up in the mobile phone bank account of those extremely poor people, which they then can spend in whatever way they believe is going to most benefit themselves", "it's the ultimate charity if you're really worried about white knights coming over to try and help the problems of some other country we don't really understand", "and the people who receive the money tend to spend it on assets like tin roofs and livestock", "so yeah, that's the best place to donate or to look if you want just an incredibly well-researched set of recommendations", "because i think that there are people listening who will have questions like those i'm going to ask, i'm going to challenge - i'm going to ask questions that i think might push in a couple of placesthe first is, are there any organizations or resources like givewell.org that are less human-centric", "and the reason i ask is that the roi seems to be measured by the number of human lives saved   are there other organizations or people who have evaluated cause-driven nonprofits, ngos, whatever they might be, that are not focused on the number of human lives saved", "william macaskill: yeah", "so there's one i actually helped to set up called animal charity evaluators", "and that's applying the same sort of - attempting to have the same sort of level of vigor of research, but who you want to help are just animals", "where should you donate", "and they have a much smaller operation than givewell, but again, you can check them out for their sort of recommendations", "in terms of if you're thinking about the environment, there i'm just less sure, actually", "givewell is starting to broaden the research that they do, so they're working with a foundation called good ventures, which is set up by kevin turner and dustin moskovich, who's one of the facebook cofounders", "and there, they're looking into a much wider variety of causes beyond just global health and global development, including things like climate change, fundamental research, policy reform, especially immigration research and criminal justice reform, and trying to look for - comparing across all different causes you could be interested in, what are those that are particularly great in scale, so it's just a very big problem, particularly neglected", "so there aren't very many other philanthropists or actors trying to solve this problem, so it's not very crowded, or particularly [inaudible], so where there's just really great programs that haven't yet been funded", "but we know they're going to make a really big differenceand some of the ones they're championing are improving conditions of animals on factory farms, improving immigration policy, improving criminal justice policy to reduce the number of people who are incarcerated, while at the same time maintaining the same level or better level of public safety", "and then also, the risks of kind of global catastrophe", "new technology is often climate change, or from developments in biology and so on", "got it", "thank you", "related question or quandary, maybe, for, i think, all the people listening", "so if you look at a given high need population", "let's just say we're looking at - you gave kenya as an example - we're looking at kenya", "the reflex seems to be to help the poorest of the poor", "are there philosophers or philanthropists out there that you respect who disagree with that", "in other words, people who say, you could give $10 to the 10,000 poorest people in kenya, but i'd prefer to try to identify the, say, 200 most promising young students who could become the leaders of tomorrow, and break the cycle of poverty in this country through policy reform, and this, that, and the other thing, engineers, blablabla", "but it's a much more expensive per person proposition probably, right", "maybe they have to be sent to the us or cambridge or oxford for education, for instance", "how are people thinking about that, and is there anyone who - it's politically safe to say, we want the focus on the poorest of the poor", "no one's going to rake you over the coals publicly for that, right", "but are there people who take the opposite approach, whose arguments you think have some validity, or that are interesting", "william macaskill: yeah, so i can think of a couple good arguments here", "so in terms of the argument for focusing on the poorest, it's just because of diminishing marginal returns for money, and the fact that in rich countries, if you're earning above $10,000 per year, you're among the richest 15 percent, 10 percent of the world's population, even taking into account the fact that money goes further overseas", "and if you're earning above $50,000 per year, then you're in the richest one percent of the world's population", "and the poorest people in the world only earn about 60 cents per day, or the equivalent of what $1.50 could buy in the us", "and for that reason, additional resources to them makes such a much bigger impact than additional resources to people in richer countries", "in my book that just came out, doing good better, i talk about this as the 100-fold multiplier", "a dollar to me is going to do less than a hundredth of as much good as a dollar going to some of the poorest people in the world", "i think there are a couple of ways in which there can be things that focus on people who are already comparatively well off, and that can do a huge amount of good", "and one is through research and innovation, so increasing that", "so a huge amount of good has been done in the past through developments in science and technology  and medical research", "so mobile phones got developed by motorola in the \u00f470s, and now cost sub-saharan africa - the majority of people own a mobile phone", "so you do get this kind of over the long-term trickle down effect as a result of research and innovation", "and that tends to get underfunded by the market", "and then a second thing is if you can kind of harness these incredible resources, which are these very talented or very ambitious or more well off people, and kind of direct them in a way that's going to do more social good", "so that's the approach 80,000 hours takes", "my nonprofit advises on career choice", "we're a small operation", "we need to focus", "and so we focus on those elite students, the kids coming out of ivy league schools", "not because we think it's comparatively important to make harvard grads a little bit better off, but rather because they're the people that are really going to be the leaders of tomorrow, or they could be shaping the world", "you want them to be doing more to improve the world, both by having more kind of motivation to do good, and using that motivation in as effective a way as possible", "and so those are a couple of ways in which i think you can do a lot of good by focusing on areas other than the very poorest of the poor at the moment", "and there's an organization that i'm involved with called questbridge that people can check out if they're interested that i think is sort of along these lines", "and it complements, in a way, the underserved students that i work with vis-a-vis donors choosebut reid hoffman and others are on the advisory board for questbridge, so people interested can check that out", "did an  interview with reid hoffman for this podcast that discusses that on some level", "if you wanted to convince people to help others, but to do it through pure self-interest, how would you go about doing that, and what would the form of giving look like", "so in other words, if you can prove to someone they will be happier if they give enough to save the life of one person per year, for instance, right", "i think we're going to get into andreas a bit", "i think that would go a long way to - and i know this sounds maybe cynical and terrible, but i don't think that saving a life is enough to get millions of people to donate money", "it sounds terrible, but i think that appealing to self-interest is sort of the trojan horse necessary to open them to that experience", "what would it look like", "and i started thinking about this very specifically over the last year also because i'm involved with various cause-driven companies, both nonprofit and for-profit", "and i took my family, took my parents and siblings on a trip to iceland last year", "it was the first time that we'd taken a family trip in 15 years or soand the anticipation of that was so much fun and made it so much more valuable to the entire family, all of the brainstorming and the researching and the sharing photos and so on, before it happened, that i started thinking of how that type of structure could be wrapped around something like cause-driven companies, whether nonprofit or for-profit, right", "so if somebody really wanted to get - just pure self-interest", "i want to improve my quality of life, my optimism, my self-reported wellbeing, blablabla, how should they do it", "william macaskill: yeah", "so i think, i mean, the psychology evidence itself does suggest, actually, that giving - i mean, it suggests a couple of things", "one is just that money is actually way less than important than we think to making ourselves better off   the relationship between higher levels of income and higher levels of happiness is really very low indeed, whereas other things, like having a really good community around you is actually very important", "having a group of friends that really like you is very important to being better off", "and so one thing is just, yeah, if you want to start doing good, especially like with the effective altruism community, suddenly you find you've got thousands of new friends who really want to support you and make you do better in life", "and that's, i think, one reason why the people who have been my peers who have started giving, actually feel, including myself, just actually feel really good about this decision", "another thing is just the direct effect of giving", "you get a kind of warm glow", "so people do tend to feel - and they've don psychology experiments on this as well, looking at people who donate rather than spending money on themselves, and people tend to feel happier", "after having donated, they feel better about themselves", "is there any particular type of donation or type of cause that has the most significant impact in that respect", "does that make sense", "i know we don't want to do this, but if we put efficacy aside, what are the characteristics of the donation that has the most persistent effect on happiness, self-reported happiness, all of that stuff", "is it the flipping through the pamphlet to choose between the goat or the chicken or the fill-in-the-blank for - the kid who's pictured in the back", "is it something else", "what are the characteristics of sort a selfishly fulfilling charitable giving event", "william macaskill: yeah", "so i don't know if there's any research done on this, but i suspect it would be, if i'm honest, not exactly the sort of things i tend to promote", "it would be things where your donation's quite public, but not in a way that comes across as sanctimonious, but just that people know you're doing a lot of good, and where you get the kind of positive feedback as a result", "so probably donations within your own community, or where you can see the kind of tangible benefits of what you're doing", "that's going to be a really big factor", "and then i guess if you're part of a peer network where you've got a number of people kind of all doing the same thing, that's also going to be - and those people who are kind of self-reinforcing", "so also saying, yeah, that's the awesome, what you're doing", "you're this really good person as a result", "i suspect that's also going to be one of the biggest ones in terms of increasing your level of happiness", "whereas purely, i suspect donating to someone just on the street, where you never hear from them again, that's got to be among the worst because that tends to sell you by making you feel guilty for a time, and then you donate in order to alleviate the guilt as opposed to this positive kind of ongoing thing where you get consistent feedback, whether that's from the community or the people you can actually see who you're benefiting", "well, it's a negative reinforcer, right, as opposed to positive reinforcer", "and if you look at dog training, or really any mammalian training, that doesn't produce a lot of enthusiasm", "william macaskill: yeah, that's exactly right", "carrots work and sticks don't, at least not in the long run", "and the kind of worry i have about fundraising in general is that you get this competition between charities, and you could get this race to the bottom where they hold up bigger and bigger sticks, and that means that people just end up getting annoyed or fatigued by these constant requests for donations", "well, right", "and we're going to talk about y combinator in a second", "but i want to make sure we come back to this because i think many people - more people would be willing to get involved with charities or nonprofits if they felt they would stop getting annoyed, or that there wouldn't be incessant follow-up with guilt, guilt, guilt, like every letter they receive", "i think a lot of people don't want to open the door to that type of haranguing and kind of incessant barking, so to speak, so they never take the first stepdoes that make sense", "william macaskill: yeah, no, that's exactly right", "well, let's just cover it now", "if you could make a plea or a suggestion to people involved with nonprofits out there and say, stop doing this, this, and this; start doing this, this, and this, what would be on those lists", "william macaskill: yeah", "i mean, one thing for sure - so i used to work as a - in the uk, we call them chuggers, or charity muggers", "people who are on the street who then harass you for $10 a month", "people seem to really hate that, as i know, having done it", "and i think that's something that's particularly damaging", "another is these pictures that you get of children in poverty with bloated stomachs and flies in their face", "and it does a couple of bad things", "one is just that it makes people really not want to get involved because it's these kind of horrific images that very naturally, you want to steer away from", "and then also, just paints this really bleak picture, and kind of quite a disrespectful picture of people in poor countries as those who are just helpless", "whereas i think if you are, like you say, doing positive reinforcement, so instead, you're like, hey", "this person donated $1000 and was able to deworm two whole schools isn't that amazing", "that's much more compelling", "and if you could get charities to kind of band together to have that approach, then i think you'd do a lot more good", "and then i think the second thing would be in terms of the amounts asked for, i think there's also a race to the bottom in terms of different charities wanting to ask for less and less", "because if you've got a choice, oh, one advert's asking me to give $10 a month; another's asking me to give $2 a month, and i've got the same feeling of gift i can resolve either way, then i'm going to donate for $2 a month", "i think that's just not an appropriate reaction if the images they're showing you are of these starving children", "and so again, i'd rather if we campaigned to say, the amount you should give is two percent - everyone should give two percent", "and then it's up to you where you give it, but that's what you should be aiming to do", "and then it's just the one-off thing, it's just this one campaign", "you don't get asked all these - i mean, this is part of a classic bit of social psychology", "you want to disaggregate costs and sort of disaggregate benefits and aggregate costs", "where getting asked to make a donation is a kind of cost and it can be a bit unpleasant, but then you want the benefits that come and the rewards you get to be as recurring as possible", "and so having different charities saying, look, this is the standard, two percent of your income", "well, maybe you could try for more, but that, i think, would be a decent amount to publicly say", "then i think people could - i mean, you could make a huge difference with this", "i think people could really get behind that and would start to have a more positive view of charity and trying to help others", "let's segue to y combinator", "so y combinator, for those people who are unfamiliar, is like the harvard all souls navy seals of startup accelerators", "and they would dislike the term incubator, but a lot of people have a better familiarity with that", "people apply", "very few get accepted, and there are some huge companies that have come out of it, dropbox, etc", "you participated in y combinator as a nonprofit, which i think is unexpected to many people, or seems like a mismatch", "can you describe how you came to apply and get accepted to y combinator", "tell me the story of how that happened", "william macaskill: yeah", "so the charity was 80,000 hours", "that's the career advice one that went to y combinator", "and we had been doing research into different career paths", "and one we recommended really highly, actually, was tech entrepreneurship", "and that was for a few reasons", "one is because we think that early on in your careers, you should be really just trying to think about the long-term", "you should think about trying to build up yourself as a person, your skills, your network, your credentials, how much you're learning", "and trying to run a startup is one of the best things you can possibly do for that, or being in the early stages of a startup as an early employee", "it also has potentially great payoffs in terms of the good you can do through entrepreneurship", "i can tell you about some really amazing companies that are doing incredible things to improve the world", "and then also, if you do get really big, if you have founded a dropbox or an airbnb or something, then you have huge financial resources that you can use to make an absolutely massive difference, as bill gates has done", "and so we were promoting that quite heavily", "and that meant that when y combinator started to say, okay, we want to do nonprofits", "we're going to open the doors to nonprofit applications where they'll just give a grant instead of an investment, a lot of people then contacted us", "and we thought, yeah, this is just a perfect fit   we have the same sort of mentality", "so the nonprofit space can be very stale, very unambitious, very unoriginal, whereas we want to be really big, and we think we can give the best advice in the world for people who want to make a difference with their careers", "and we think we can reach - we want to reach everyone's who's graduating from university[inaudible] we're focused on numberswe actually are thinking in a quite similar way to a full perfect startup", "y combinator seems like a really good home", "so i made the application, and it's a very funny process because there's the application form and a one-minute video", "so everything is incredibly condensed in terms of what the partners actually reviewan application form and a one-minute interview, a one-minute video of yourself", "and we just got drunk and filmed it", "what are you supposed to put in that one-minute interview - excuse me - video", "you incepted me", "what is the content of that one-minute video supposed to be", "william macaskill: yeah", "so in that one-minute video, i mean, you can talk about anything", "sometimes it's just a conversation between founders", "but for us, we talked about - actually included the warm-up that we were doing", "so for about 20 seconds, it was just us singing", "but then talking about what exactly 80,000 hours does, what's the problem, how we're going to grow, why do we think we're a team that's good enough that we're actually going to be able to become an absolutely massive organization", "that was kind of how we approached it", "but the key thing is just - and this is amazing how often founders fail to do this, is just actually conveying what you do", "because you get the curse of knowledge where you're so invested in this project that you've got so much detail and so much on your mind", "then when you actually try and convey it to someone who isn't as familiar, then you completely bastardize it, and people have no idea what you actually do", "yeah, sort of drown them in the minutiae, and they can't see the big picture", "william macaskill: yeah, exactly", "and this is something that the y combinator partners were so good at - every single week, we'd just have to give the one sentence description of what we do", "and for us, now it's gives career advice for people who want to make a big social impact in their lives", "so just actually explaining that and explaining exactly how you do it was just absolutely the key thing", "and when were you at y combinator, then", "william macaskill: so yeah", "we were there summer batch, so just the last few months of the summer, basically, in july/august", "july/august 2015", "william macaskill: that's exactly right", "what were the most important things you learned or skills you developed at y combinator", "william macaskill: yeah", "so the whole thing felt like this exhilarating learning experience, a whole new lens on how you build something to get very big", "and so a lot of great pieces of advice", "one is just to focus on the product basically exclusively", "you will constantly be tempted to spend your time doing things that make yourself look cool to your friends and family, but that aren't actually making a better product, and that aren't therefore helping your growth", "so you'll be tempted to do [inaudible], you'll be tempted to hire a lot of people because then you can say, \"oh, well, we've got 20 people on the team.\" whereas hiring just actually takes a lot of time away from just trying to build a better product", "the other thing is just picking your metric", "so for us, that's the number of people - ultimately, that's just the number of people whose plans we've changed in a very significant way, and focus on growing that metric by 10 percent every week", "so we'd been growing at something like - kind of doubling in size every year, and that makes us in the top one percent of charities, i think", "10 percent every week, that's 142 times over the year", "it's just a totally different kind of level of ambition", "and that really gives you focus", "so you're ensured on doing just what's going to make your company, or in our case, charity, bigger and better every single week, and just doing whatever it takes to hit that 10 percent growth target", "yeah, that's a focus on product in all of - i have about 40 angel investments now", "and if you look at that sample set and pick out the biggest winners", "and some of them are on paper still, but a lot of them have already have large community events", "all of them ruthlessly focused on product, to the extent that if i brought them an amazing press or biz dev, business development opportunity partnership of some type, they would say, that looks great, but we're heads down on product   just not the right time", "but we'll be sure to reach out in five months, six months", "and it's that ability to say no to focus on product, which as you know, in this day and age, is the best approach to marketing and customer acquisition that you can take, since word travels organically if you take that approach", "easily the most common denominator when you look at the homeruns in my portfoliogoing to come back to yc in a second", "but you mentioned startups making a big difference", "and one of the startups i'm involved with, for instance, is duolingo", "and duolingo now has, i want to say 100 million plus users who are learning languages for free on duolingo", "and the founders include louis van ann, who was effectively the creator of captcha and recaptcha, which was sold to google", "and it's a very brilliant model", "i mean, they're pulling real content offline, or from clients who are paying to have things translated, and using the crowd to translate while simultaneously teaching them different languages, right", "so ostensibly, you end up in two very interesting positions", "you have hundreds of millions of people learning languages more effectively than through paid programs for free indefinitely", "and then you also have the ability to generate revenue through translation and certification and other things", "and then you also have the ability to rapidly translate", "so you could crowdsource, say, turning wikipedia into some lesser known language in 50 hours of total time, which would be, of course, thousands or tens of thousands of hours of human time, but it would be simultaneous through this program, right", "so they are, i think, going to have and are having a huge impact", "what are startups that come to mind for you, for-profit, that are having a huge impact", "william macaskill: yeah", "i mean, i think that's a great example", "and one of the things with for-profits is you can just get so big, and get so big so quickly, so being able to reach 100 million people is absolutely phenomenal, and quite hard to do if you're functioning as a nonprofit because you currently haven't the fan base", "my favorite example of a for-profit company making a really big impact, again, set by someone in the effective altruism community who's also a y combinator alumnus, is called waive", "and it makes remittances cheaper, basically", "so globally, remittances, sending money from a country that you've immigrated to back to your home country, which is typically poorer, to your family there, is an absolutely huge deal", "so there's about half a trillion dollars sent in remittances every single year", "and compare that to overseas development aid spending, it's actually several times as great", "but if you're a kenyan in maryland, and you want to send money back to kenya, it's a real hassle", "you have to go a western unionthe western union takes 10 percent", "and what waive are doing is enabling you to send money mobile to mobile, so it's much easierand they also only take three percent", "and they're growing phenomenally fast at the moment", "they've already got thousands of users, and tens of thousands of users that are moving millions of dollars, even though they only just set this up and launched about six months ago", "and the potential there, if you just do the math, if they're able to really make a significant change to the amount of money that's flowing to poorer countries in remittances, there's tens of billions of dollars every single year going from richer countries to poorer countries and kind of not getting taken by these middlemen companies", "it's got an absolutely astonishing kind of opportunity to have a really big impact", "so if you reflect back on your time at yc, as the kids call it, what were the most common debates that you had with other participants in yc, or with the partners", "william macaskill: yeah, that's a good question", "yeah, i mean, one thing that was very common was how much time to spend on things that are going to grow your user base rather than product", "so they said for advice, just always focus on the product", "but then there's always going to be exceptions, and you always wonder, well, is this one of these exceptional cases", "and that was just definitely a recurring issue because it's kind of hard to make the judgment call of, well, actually, we've already got this thing, and you're going to have to do some amount of distribution", "so that was really a kind of ongoing thing, as were all the - maybe a lot of the biggest debates were just - so paul graham is the founder of y combinator, and he has these essays, and paul graham is something of this kind of guru or god amongst the y combinator startup community", "and he has these teachings through his essays", "and then when do you deviate from the teachings of sort of -  when do you violate the scripture", "william macaskill: that's exactly right", "that was the ongoing thing", "so similarly, another piece of advice was don't take any investment during the period of y combinator", "it's just a distraction", "just focus on growing, and then do all that after the demo day, which is the big presentation when you pitch to 450 investors in a big room", "but then people would get approached by angel investors or vcs, and the question would be, well, actually, should we be taking this", "it looks pretty good", "so again, there'd be ongoing debates about when should they violate these rules", "and paul graham even acknowledges this", "he says every single year, he gives the same advice to startup companies", "every year, everyone ignores it", "and then every year, they say later on, i really wish we'd listened to this advice", "so that was kind of played out in many different ways, actually", "similarly, for recruitment as well, we've got something where they say you want to have this exceptionally high bar for who you hire", "and you either want to be spending all your time on the hire, because getting the best team, especially the early team, is just so vital", "it's the most important thing", "but if you're going to be doing it, it has to be absolutely full-time", "the airbnb founders, it was six months before they hired their first employee because they wanted them to be so good", "but again, there'll always be these questions of, well, we could do more if we hired someone now", "is this one of those exceptional cases where we should violate that rule", "so that was the kind of theme in terms of the debates or things that were on peoples' minds.yeah, that's another one where pascal's mugging will kick you in the nuts, right", "because if you're like, well, there's a one percent chance that they could be the michael jordan of exactly what i need, so let me hire them", "i mean, that's a kamikaze run at a ship, so you have to be very careful", "where do some of your favorite philosophical frameworks have trouble in the real world", "william macaskill: um-hum", "yeah, i think all over the place, probably", "so i mean, a big thing is just, the real world is just so messy", "so you've got this idea, okay, i just want to do the most good", "i want to help as many people as possible by as much as possiblethen actually implementing that is much harder to do, so", "in the early stages, for example, of giving what we can, when we were doing the search into charity effectiveness, we made kind of certain assumptions about, say, the quality of academic evidence, where there's this body of kind of research of economists that we were really pretty happy just to trust", "because we're like, look, these are the scientists", "they really know what they're talking about", "they're giving these numbers", "we're happy to go with these numbers", "and it turned out, actually, loads of researchers would be kind of crappy", "we really couldn't trust them in the way that it would have been hoped for", "instead, you've just got to go a lot more with very in-depth, independent investigations of the evidence yourself", "and that was something where you've got this kind of philosophical motivation, and then you make an assumption, which is that the people doing the experimental work, the empirical work, that you can just kind of trust what they're doing", "turns out that's really sadly not the case", "science is a lot more broken than you'd think kind of coming into it", "and so that was maybe one case where we made some assumptions about how best to do good, but actually, when you have to start confronting the really messy real world, things got a lot more complicated", "did you ever find - i don't what accent that was that i just threw out, but that's okay", "did you ever find, when surrounded by startup founders at y combinator, that you felt demotivated in any way because you've pledged to donate everything you earn over around $36,000 per year to whatever charities you believe will be most effective", "do you find that that is ever a demotivator, the lack of that financial incentive", "and i only ask because the ambitious set, the smart and ambitious set who make it into y combinator, they're not purely one-dimensional from a financial standpoint", "but many of them want to build large companies to get exceptionally, exceptionally rich, among other things, right", "and there are case studies of the incredible realities you can create for yourself if you win one of those lottery tickets, or if you can execute well enough to become one of those lottery tickets", "what was your experience like", "william macaskill: yeah", "so i think in terms of my personal motivation, it's almost the opposite, i think", "since i decided, okay, i really want to use my life to make a big impact, including making this commitment to give away most of my income, that's made me way more motivated   because now it's not just kind of me on the line, it's like all these people i'm aiming to help", "not all the time, because i've grown out, but sometimes it's the feeling of kind of urgency you get in like a war situation or something", "you're like, whoa, this is a crisis", "it's an emergency", "you've got to do somethingand if i was just out for doing myself, i think i'd be much happier to have a somewhat more relaxed life", "but i do feel, definitely doing y combinator, i'd feel envious of the for-profit companies in some ways", "so the two ways i think it just - yeah, three ways, maybeone is just how quickly you can grow because you can get investment", "so the top y combinator companies were getting three million dollars in investment two days after demo day, whereas if you're a nonprofit, then you were just having to go around soliciting donations", "we have really great donors who are just very rational, and it's not nearly as arduous for us as it is for many other nonprofits", "but even still, it's just a much slower process for growing", "second is in terms of the scale you can reach", "i think something like only 50 charities have grown to more than 50 million dollars of revenue over the last 40 years, whereas airbnb, it's just less than 10 years,  grows to a 20 billion dollar company", "many other examples of this as well", "and given the kind of scale of our ambition, that's also something that makes me think, yeah, actually, that's a really pretty good model", "and then, yeah, the final thing is, in terms of what sort of talent you can attract in as well", "working as a nonprofit, you have the kind of - it's much harder to be able to pay competitively to try and get in those people who are just too ambitious themselves", "you've got a much smaller pool of people, those people who are much more motivated by the kind of impact they're going to haveand that's an extra difficulty as well", "so it definitely made me appreciate the benefits of kind of for-profit models if you're wanting to have a really big impact", "this is another question i think a lot of people wrestle with", "give now or give later", "and the reason i ask is that if people were to survey the philanthropists currently most famous for rationally giving and making an impact, you would find people like gates, for instance, right", "but the reality of gates is that - and no offense, bill, but he was a predator who became an icon who became a philanthropist", "you would not consider him an altruist for the first few decades of his career", "and so there are people - i actually had someone say to me not too long ago, mother theresa was a narcissist", "bill gates, with a strike of the pen, can do 100 times more than she ever did in her lifetime", "and therefore, if you have even a small likelihood of developing the sort of dynastic wealth of someone like a gates, you're better served, rather than kind of shaving off speed by donating along the way, to focus all of your efforts on building an empire that you can then use for the greater good", "and no doubt, this is not the first time that you've heard this type of thinkinghow do you respond to that, or how do you contend with that type of thinking", "william macaskill: yeah, so that's such an interesting question", "actually, when i'm giving talks, i often kind of judge audiences by whether this question comes up", "so i think this is a good audiencebut no, so it's interesting", "so i think, yeah", "i mean, firstly, i think you can do, as gates did, just a huge amount of good by what i call learning to give, and i've promoted that, where you aim to do good through your ability to donate or through a private contribution of your labor", "and i think it's not the right path for everybody, but i think a lot more people should consider it than currently do", "in terms of when you should be donating, i think there's a few reasons on either side", "so if you've got these amazing investment opportunities that are just going to really pay off, then you should definitely take them, where going to college is the clearest example", "if you're the age of a teen coming out of high school, then you could just start earning money and donating it right away, but that would be a real mistake", "you should definitely get a degree, especially if you can go to a good university, just because of the impact it has for the rest of your life", "and actually, in general, when we give advice at 80,000 hours, we think that people really underinvest in the long-term with their careers", "because most of your hours that you're going to be spending working is going to be after the age of 30", "and also, that's when you're more influential", "so you're running an organization rather than turning for them", "whereas a lot of people who want to do good immediately go and work at a nonprofit where they're not going to get as good training or skills, network, credentials, money as they would at other places, like the for-profit world, or sometimes further education as well", "so i think a lot of the time, actually, people should be investing more than they dowhen it comes to the idea of just, okay, i'm already earning a loti'm just going to invest it all again on building up my own organization", "i'll donate at the end of my life", "alarm bells ring for me a bit because a lot of people say that and then never actually follow through", "oh, i'm sure, yeah", "william macaskill: and so i think minimally, you should start donating a pretty significant percentage just to get yourself in the habit of it, just so you know you're not telling yourself this lie", "i think there are other thoughts as well", "so donating has its own sort of compounding", "it's like a sort of investment", "so when someone in kenya buys a metal roof, they get this amazing return on that investment", "it's like 14 percent per year or something", "so if you're giving to that poor household in kenya who then buys the metal roof, that money that you give them compounds over time", "you don't see it because the effects are kind of diffuse, but you've made the whole country that little bit richer in a way that compounds just in the same way as if you'd put it in a bank", "on the other hand, though, you also just might really not know what the best ways of doing good are", "and so you might want to wait until you've just got better information, or you have better views, or are actually able to think about this", "and i think that's maybe, with a lot of entrepreneurs, kind of what's going on", "maybe you feel this yourself as well", "i've got so much going on", "if i really want to do a really good job of philanthropy, that takes time", "and so i'm just not able to think about this", "i'm going to have to punt it to a later stage", "and so i do think there's a reasonable argument to be made there, but maybe the things you could do are start kind of binding yourself to the mast a little bit", "maybe you can make some public commitments, make some big declarations publicly such that you know that if you back out with them, it's going to be really embarrassing", "or you can take a pledge", "so i'm the advisor of an organization called the founder's pledge, which provides you with a contract so you can legally bind yourself to give at least two percent of your income, or two percent of the profits that you make when you exit your company", "and i think that's again one of these things where you can say, okayto begin with, i'm just going to focus on building this thing as much as possible", "i know that i've actually locked down my intentions, so i'm going to follow through on this later on", "that's the founder's pledge", "william macaskill: founder's pledge, that's right", "how many people have made that pledge to date", "that's a contractual obligation", "william macaskill: that's a contractual obligation", "who is the counterparty", "who are you contractually obligated to", "william macaskill: so the way that works is you can still donate anywhere, ultimately, but it has to have an entity in the contract just for legal purposesso you donate to this organization, the founder's pledge itself, that would then redistribute the money wherever you wanted it to go  i see", "william macaskill: so you don't have to make a decision about where the money goes until you're actually making the donation", "they act a trustee of sorts", "william macaskill: that's right, yeah, a kind of intermediary", "got it", "you write, \"following your passion could be a mistake.\"  william macaskill: yeah", "could you elaborate on that", "william macaskill: yeah", "so when it comes to career advice, there's all these slogans that go around, the chief of which is follow your passion", "and the idea is kind of like the idea of having a soulmate or somethingyou just look inside yourself and you've got this calling, and it's like, oh, i should be an artist", "and then you see that calling inside yourself, and that's what you should go and do, and that's the way to be happy", "and i just think this is terrible advice, and that's for a number of reasons", "so one is just that most people don't have work-related passions", "there was one study that found that most people who were really passionate students, they were passionate about things like arts, music, sports, things that are incredibly difficult to actually work in precisely because everyone's passionate about them, so everybody wants to pursue them", "so it's not really taking what the world needs into account", "and it sets you up for kind of anxious soul-searching, or then trying to pursue this thing that just statistically speaking, you're probably not going to be successful at", "but i think it also just misconstrues that nature of finding a satisfying career and satisfying job, where the biggest predictor of job satisfaction is mentally engaging workso its' the nature of the job itself", "it's not got that much to do with you", "well, obviously that is important to some extent", "it's whether the job provides a lot of [inaudible], it gives you good feedback, allows you to exercise autonomy, contributes to the wider world", "is it actually meaningful", "is it actually making the world better", "and also, whether it allows you to exercise a skill that you've developed", "and then there's the final thing where you might think following your passion in terms of do something you're good atbut the thing is, if you're just starting out on work, you're probably just not that good at that many things that are work-related", "when i was graduating, i hadn't really done any management or fundraising or marketing or anything of the skills that actually get used day-to-day in work life", "and so what you should be thinking when you're first coming out of university is you should be thinking like an experimental scientist, or investigative journalist or something", "you should be thinking, well, what are my hypotheses about the things i could become good at", "and then actually going into the world and then testing that, finding out, hey, maybe i could become good at coding, and that's something the world really needs at the moment", "there's such a huge demand for coders", "and then actually going out and trying that, because that's the final thing, is just people's preferences and passions change massively in ways that people systematically underpredict", "so if you think back 10 years, what were you like 10 years ago", "what were the things you were really passionate about", "they're probably quite different from the things you're passionate about now", "but yet when we think in 10 year's time, we think, oh no, i'm set, i'm the same person now", "and so really, what you want to be doing to begin with is building up a broad array of skills, figuring out what other things i can become good at", "and that's the much better way to lead to kind of a successful and effective life", "i agree on all those points", "i think that there's another bullet, which is - i wrote an article years ago", "i think it's just called \"the dangerous myth of the dream job.\" and i think the other issue - well, there are two issues that i'll underscore", "the first is, as you said, humans are very bad at predicting what will make them happy", "extremely statistically bad", "there's this great book by daniel gilbert called stumbling upon happiness that goes into some depth on this", "now, that's great", "a pretty depressing conclusion", "how do you address it", "i think the second bullet is realizing that one of the best ways to extinguish your passions sometimes, if you are using it to be synonymous with hobbies", "let's say you surf on the weekendsyou wake up on a saturday and you surf every saturday", "you love surfing; therefore, you think you should follow that as your passion", "very different, that experience, and the purpose of that experience is very different from waking up at 6:00 every morning to take investment bankers out to surf every morning from monday to friday, right", "and so i think people overestimate the persistence of their enthusiasm in that switch from optional activity, electional to obligatory", "william macaskill: yeah", "and being in philosophy, i'm very familiar with this", "so i'm really lucky in terms of the position i got, but there's far more people wanting to do philosophy as a career than actually make it", "and you see so many people like this, who got into it because they really love the subject, they just wanted to learnthey found it incredibly intensely satisfying", "and then they find out that actually in the real world, they've got to work to do thisthey've just got to jump through a lot of hoops and do loads of networking and bureaucracy and admin, just as if they were in any other job", "and it can be really dissatisfying", "you can end up - it can actually be pretty tragic, where you end up hating the thing that you used to love the most above everything else", "which is very common, extremely common", "so you are a very effective young man, i would say", "william macaskill: thank you", "you're welcome", "i think it's pretty easy to objectively assess", "you've achieved many things that it would take people a lifetime to achieve, if they achieve it at all, so congratulations, first and foremostbut the question i'd love to ask is what book or books do you give the most to other people as gifts", "william macaskill: um-hum", "yeah", "so we talked a bit about the moral philosophythat was peter singer and derek parfit", "so i'd definitely give them", "but in terms of just improving your life and being more effective, there are two i'd mention", "one is mindfulness, by mark williams and danny penman", "and having had sam harris on the show, obviously your listeners will know about this, but mindfulness meditation's the most - i don't know   it's kind of like this magic bullet technique that kind of science has just recently cottoned on to where, in effect, you train yourself to be more in control of your thoughts and emotions by realizing that the current thoughts and emotions are not you", "they don't define you", "they're propaganda, and it's up to you to choose how you react to them", "and our instinctive way, which is to fight with them, is actually counterproductive", "instead, you want offset them with warm and welcome kind of curiosity, almost", "and then that means you have the ability to deal with them as you like", "and that's got the most evidence base in terms of - it basically seems to improve everything, but in particular, mood and self-control", "who are the authors of this again", "william macaskill: mark williams, a professor at oxford in psychology who is the real kind of champion of -  you're really part of the oxford mafia", "william macaskill: i know, i know", "it's all so nepotistic", "but that was a coincidence, though", "he's actually one of the few authors i went to just to say, look, this book, it's significantly improved my life", "you should be very happy with what you've achieved", "awesome", "william macaskill: and then danny penman, i think his name is, who is a kind of journalist, but also promoter of these ideas", "and it's just a really good course for it", "i like it because i'm a big science fan, so i hear something like meditation and i get a little bit freaked out", "it sounds a bit hippie for me", "whereas this is just - it's almost comically dull, in fact", "i mean, they give these kind of guided meditations, and you're used to hearing this kind of female, high-pitched, dreamy voice, and instead, you get this broad midlands english accent saying, \"now, sit on a rug or a chair or on a bed, and close your eyes.\"   and it's really very kind of surprising when you first listen to it", "it's just like the worst dad bedtime story ever, but effective nonetheless", "william macaskill: but then really good if you feel kind of intuitively a bit skeptical of that sort of thing because it's a very friendly, very kind of accessible introduction to mindfulness meditation", "and it provides you with a course of eight weeks, where you do a series of guided meditations", "and i did that course, and it's one of the things i think has had a really significant impact on my life", "do you have a daily meditation practice now", "william macaskill: i actually don't, but i'm going to start again", "i mean, i think there's two things", "yeah, i think i'm going to start again just after the gym because i go the gym first thing every morning", "and then after that point, it can just be 20 minutes, breathing, where you first focus on your breath, and then extend that feeling of awareness to your whole body", "i still meditate if i'm feeling stressed or anxious about something", "it's a really nice kind of go-to activity that you can do to kind of put yourself - kind of reset yourself", "but then also, the other thing is just it starts to affect your entire approach to life", "so you will start to feel the rising panic, and you're much more in tune with your bodily reactions that then turn into thoughts", "and then again, you can kind of catch those bodily reactions to begin with", "again, kind of slow down your breathing, focus on the breath, and then realize that it's up to you how you want to respond", "and that can be very powerful because it means you have much more choice about your emotional reactions to things", "what was the second book", "william macaskill: so the second book is the power of persuasion, by robert levineso i'm really in favor of matter skills", "just these kind of general purpose skills that can improve your effectiveness in all areas of life", "and just the ability to be convincing to sell ideas and to persuade other people is one of the most important of these skills, i think", "i like to think of myself as taking laziness and making it into a virtue because why do something when someone else could do it", "if you can make that into a virtue, then suddenly, you find you have all these volunteers helping you with this thing you're trying to create, and they turn into employees, and then they're away doing the sort of stuff that you could have instead just been slogging away on yourself for years", "so the power of persuasion", "william macaskill: the power of persuasion", "and i don't think it became that popular, but it's the best book on persuasion that i know of, actually", "levine", "william macaskill: yeah", "and it's quite a lot more in-depth than things like caldini's power of persuasion and some of the other books in that genre", "it's incredibly interesting, and really lays out different principles, the keys ideas for persuading someone", "like norms of reciprocity or escalating commitment", "and it also just really shows how being persuasive a lot is often just about being a very nice, authoritative, genuine, honest person", "so the key aspects of being persuasive are honesty and authority", "and many people, they think, oh, well, i want to become someone who can be persuasivethey then turn into these kind of sleazy secondhand car salesman types", "and that's exactly the wrong thing to do", "instead, it's actually about being this transparent person who really knows their stuff", "and yeah, i've found that kind of fairly useful, especially as someone who is trying to - my life is about selling people on certain ideas, ideas of effective altruism", "well, i think everyone's lives are about selling other people on their ideas", "william macaskill: yeah, basically", "i mean, it comes up absolutely everywhere", "and it's just very thorough, very in-depth, and really goes to the level of breaking down into really concrete principles", "like earlier, i mentioned you want to aggregate harms and disaggregate benefits", "so it's more enjoyable for you to win $50 one day and $25 the next than it is to win $75 one day", "whereas if that were a cost, then it would be - you'd prefer to just lose $75 at once rather than have two distinct losses", "right", "william macaskill: so again, it goes to the level of very specific recommendationsand then also has amazing case studies of - it does go to the best stories of working with the very best salespeople in all different areas of life", "and so it is the best book that i've read on that topic", "i'll have to check it out", "your morning ritual", "you mentioned working out first thing in the morning", "what does the first 60 to 90 minutes of your ideal day look like", "william macaskill: yeah", "so in terms of morning routine, i think the biggest, i think maybe the single piece of productivity advice or productivity improvement i made was sleeping enough", "people's needs for sleep just varies massively from person to person", "some people can just sleep four hours a night, and they're very lucky", "i'm not one of those people", "and coming to accept that was very important", "so i aim to sleep nine hours a night", "and then when i wake up, it's really about getting up and going", "when do you wake up", "what's your normal range", "william macaskill: yeah", "typically, about 9:00 am, so not a super early riser eitherreally not much of a morning person, actually", "so it's typically about 9:00 am", "and then, yeah, it's just about getting up and going", "so i eat things that i can hold in my hand", "i really hate cereal", "i hate thing where i have to spend a lot of my time", "because also, the morning's my peak time in terms of my mental performance", "and so i typically eat breakfast bars, which i'm sure you're going to chastise me for for being unhealthy", "but that's what i do in the morning", "go to the gym, again, and that's probably the second most important piece of product of the [inaudible] advice, which is just get exercise", "again, because i feel like in terms of my life and who i've come to be, almost all of it is in terms of the highest quality work i'm producing, rather than how many hours i'm producing", "so the thought of, oh, i can sleep less and then produce more hours is just completely false economy", "instead, it's just how can i produce the highest quality work", "and for that, again, just exercising in the morning is the most important thing", "what type of exercise", "what does your routine look like?william macaskill: yeah", "so i've suffered from fairly severe back pain over the last year and a half, so that's changed things quite a lot", "and now, so my favorite exercise, which i was able to do when i was in cambridge and not here because they don't have the machine, is called jacob's ladder", "do you know it", "i do, yeah", "maybe you could describe it for folks", "william macaskill: i'll see if i can describe it", "so it's wooden bars forming a ladder around a conveyor belt", "so they're constantly going down and you're constantly climbing up", "so it's at about 45 degrees, so it's not vertical", "if you ever decide to climb up a ladder, you get tired pretty quickly", "and you're attached to the machine so that you're able to set the pace as well", "so it's kind of like a treadmill, except you're just climbing up these bars", "and it's great for me because it's low impact, because i can't do high impact stuff at the moment", "but it's incredibly tiring", "i remember when i first did it, i could do about two minutes, and then i would be completely conked out", "and then i built that up over time", "and it's the most - you feel like your entire body is just completely spent by the end of it", "yeah, so it's my favorite exercise", "and then so how long does that workout last", "william macaskill: about an hour", "if my back's bad, then i try and focus it to more like an hour and a half", "but a lot of that time is spent doing physio exercises, so", "how did you hurt your back", "william macaskill: yeah, i don't actually know", "i think most cases of back pain actually don't have a clear problem", "but i think it was bad postureso my best guess as to what was going on is anterior pelvic tilt, so where your pelvis just tilts forward too much, and you kind of stick out your belly kind of beer belly style", "and so from there, the key is to really strengthen your glutes and your abs, stretch out your hip flexors and your lower back so that you're strengthening the muscles that are pulling your pelvis back and stretching out those that are pulling it forward", "and you get all these problems from sitting on that day", "i would have terrible posture as well, so i've been dealing with that a lot using an ergonomic kneeling chair, experimenting with a standing desk, and in general, learning a lot about posture, because really, i think the kind of common conceptions of what good posture consists of is just completely wrong, actually", "yeah, people think it's about sitting up very straight and very rigidly, whereas actually, it's more about getting the curve of your spine right", "so having your hips tilted too far forward so that your lower spine makes your belly stick out, that's a very common problem", "and then also having your shoulders kind of hunched forward, and then your neck and head are kind of like a duck, another very common problem", "and so actually, if you want to test your posture, you can just stand against a wall, and you should only have two inches between - so just standing up straight against the wall", "you should only have two inches between your spine and the wall, and between the kind of curve of your neck and the wall", "and for almost everyone who does that, they'll find, especially at the neck, there's just a much bigger gap than there should be", "yeah, that's also hard if you have a horse ass like i do", "a sort of kim kardashian ass", "but so for the back, a couple of things that might be helpful, where do you feel the pain in your back", "and this could be referral pain and not the - the sensation of pain might not be the location of the pathology", "but where do you feel the pain the most", "william macaskill: yeah, so it's very lower back", "very lower back", "so a couple of things that you might find interesting to play with there, if it's the low back", "it would be number one, and you can check out kelly starett, maybe you've seen his stuff, mobility wod", "he's been on the podcast as well", "but try to get the head of your femur to seat at the back of your pelvis", "so by sitting constantly, it tends to get pushed to the front of the hip capsule, and it causes all sorts of issues and soft tissue changes and whatnot", "so if you look at exercises, and they're pretty easy to do, just on your hands and knees, and you lift one leg up and move your weight around as you apply it to one legbut if you were to look up sort of seating the femur in the pelvis, and kelly starett, i think that could be very helpful", "and then secondly, have you considered using or used inversion tables or gravity boots so that you can -  william macaskill: no", "so i've found this to just be tremendously valuable, where i'm decompressing my spine and putting myself into a state of traction", "i try to do it at least once per day", "and most frequently, i will do that at night", "so i'll hang from my - try this out, because i've talked about this before on the podcast, and i've had literally dozens of men specifically, but my audience is - or the people who listen to the podcast are about 80 percent male - come back and say that they've eliminated years of back pain doing this", "and i'm not a doctor, of course", "this isn't medical advice", "but if you hang from your hands in the morning and then invert yourself at night for a short period of time - and if you can't invert, there are other options", "but you could look at teeter hangups, t-e-e-t-e-rthere are different models", "but teeter hangups", "i use the bootsthere are risks involved with hanging upside down like batman from a bar with boots on, obviously", "you could use the inversion table", "i just use the boots", "and if you can't do either of those due to space constraints, travel, or whatever, there's also a device called the lynx, l-y-n-x, which allows you to put your lower back into traction on the ground", "and it's very small", "i have one about 15 feet from me behind my couch", "and making it a habit, just as an experiment, to hang twice a day, once from your hands, and then again from your feet, if possible", "and particularly for that, like illi epsoas pelvis low back complex, i think you could find - that would be a worthwhile experiment", "william macaskill: this is great", "i thought i knew all of the back pain remedy tricks, but you've educated me", "i'm am going to try this tomorrow", "you could also, if you want to enjoy some masochism, but potentially reverse some of the soft tissue issues that you have, no doubt, in your pelvis from the sitting and the sort of kiphosis lordosis, that upper back rounding and then the anterior pelvic tilt, that sway back position, is you could find an art practitioner", "i'm sure there are - i don't know if - there's probably one, at the very furthest from you - maybe it's farthest", "i always screw those up - london", "and art is active release technique", "and they'll form their fingers into a ridge hand and dig it three or four inches into your pelvis and have you move your leg around", "it's extremely uncomfortable", "you might need a safety word", "but that can have a tremendous effect on mobility and the gliding of adjacent tissues and things like that", "so those would be worth checking out", "but i don't want to make this about me spouting off", "but since i know a lot of people who have suffered from low back pain - i previously suffered from low back pain, which i do not suffer from anymore.william macaskill: perfect", "that would be a suggestion", "and the other things is, what i've found is, standing at a standing desk all day long is very challenging, particularly if you're moving from location to location", "if i ensure that i walk an hour a day, which we're really evolved to do", "we've made a lot of compromises from an evolutionary standpoint to be able to walk for long distances", "but that also helps to keep that hip complex functioning normally", "and you're getting, at that point, sort of a high volume of low intensity stretching, which is very valuable", "so that would be my two cents", "william macaskill: well, it's a big deal", "i mean, so many people, it's like a plague or something, the number of people who suffer from back pain", "and then it just can be completely debilitating", "i've lost months of productivity as a result", "so what i would - and you can speak to your pt about this, but i think that oftentimes, the reason people have low back pain and then cannot squat is because they don't squat enough in the first place", "so the hanging, if you were to do that for a week, see how you feel, and then find a good olympic weightlifting coach, not power lifting coach", "find a good olympic weightlifting coach who can train you to do overhead squats", "and it may take a long time for you to get to the point where you can do proper overhead squats where you're not losing lower back stability", "but that can be a completely game changer", "i mean, i'm 38, and my hips and knees are better than they've been in probably 15 years", "and i directly attribute that to regular deloading and decompressing of the spine, as well as a regular squatting practice, where i'm squatting every day, even if it's just for five repetitions with 45 pounds on the back, or in front of me, or overhead", "so that's a rather massive digression, but that's okay  william macaskill: well, you may have, yeah", "let me know how it goes", "william macaskill: yeah", "you may have given me months of extra work, so be happyhopefully it'll take away the pain", "yeah, i hope it helps", "i know how debilitating it can be", "do you have any evening rituals, any evening routines for winding down", "william macaskill: yeah, i actually really don't have an evening routine", "i mean, except insofar as i always take an hour or two off before going to bed because i used to work until i wanted to fall asleep", "but that's just again this false economy because it means you just wake up much less energized", "and again, it's just eating into peak productivity time", "i travel a lot, so if i need to bet set in my sleep, then i take melatonin", "and then i focus a lot on getting high quality sleep if i can", "so most important there, just completely shutting out light so that you're not waking up in the night at all", "but in terms of something to decompress myself, normally just the regular things of seeing friends or reading", "generally try to avoid watching tv or anything that's kind of bright unnatural light", "speaking of bright unnatural light, what are you favorite documentaries or movies", "william macaskill: so i think by far, my favorite documentary maker is louie theroux", "i don't know how popular he is in the us", "he's a bit of a uk institution", "have you heard of him before", "i've heard of him, but i couldn't name any of his work", "william macaskill: okay", "i mean, the most interesting is louie theroux's wild weekends", "he tends to go to places in the us, to these weird subcultures", "and he does exceptionally well at becoming involved in those subcultures", "so examples are neo-nazis, survivalists, the westboro baptist church, swingers", "he often goes to prisons", "you have porn, cosmetic surgeons, and the black power movement", "and he come across so bumbling and naive that the people he's filming then completely reveal everything about their own crazy lives", "and that's louie theroux, t-h-e, go ahead", "william macaskill: t-h-e-r-o-u-x", "that's right", "and it's incredibly powerful because you see him interacting with these neo-nazis, and they're grilling him on whether he's jewish", "and he just keeps telling them he doesn't want to answer", "and you see them, the parents are getting their children to bounce around a swastika as kind of morning playtime", "and you think, wow, i'm so happy i'm not one of these people, and so enlightened, because they're so mind-killed", "they're so completely captured by this lone ideology", "but it makes you think, wow, what mythical things do i believe just because of the people that i'm surrounded by", "all these kind of cultural things", "because they're just completely convinced of this worldview", "or people who are looking for ufos all day, or people who are certain that the government is going to come and crack down, or the westboro baptist church that thinks that literally everyone is going to hell apart from them", "and it makes you think, yeah, well, maybe there are things i believe myself that are just - in the future, will be looked back upon as crazy as i'm looking at these communities and thinking they're crazy", "oh, i think that's no maybe at all", "i think it's 100 percent certain", "i mean, i think everybody should take the approach of good doctors, or i should say the sort of perspective of good doctors, which is 50 percent of what we know is wrong", "we just don't know which 50 percent", "william macaskill: yeah, that's exactly right", "and i think most people don't tend to act that way", "much too accepting of the status quo", "oh yeah", "and it's just like the quote that i always use and no doubt should implement more in my own life, although i try quite hard, is \"when you find yourself on the side of the majority, it's time to pause and reflect.\" that's mark twain", "but some people interpret that to mean the majority of, say, the us, whatever their nationality happens to be", "and i would just say, no, no, no", "even the majority of your friends, if you have a narrative that you're telling yourself and it's within a peer group, even if it's 10 people, 20 people, you should really examine that", "have a regular check-in", "william macaskill: and i think politics is the one that's the key, that's the biggest influence here, where - i don't know", "people will identify very strongly as very left wing and very right wing, but it all strikes me as a very strange thing to do because they're this package of very different ideas that are associated with the left or associated with the right that don't have any resemblance to each other", "like why on earth should your views on abortion be related to your views on an optimal taxation policy", "those are completely distinct issues, yet they come in these packages", "and i think it's because we're all monkeys walking around wearing suits", "we want to form tribes, and then we start forming tribes based around, say, political identities", "but then that means you'll just start to buy a package of views instead of just looking at each one on their own merits", "oh, i think - yeah, that may be a separate conversation", "i think humans can learn a lot about themselves and their biases by reading at least one book on chimpanzee behavior", "there's one in particular that's popped up a lot in my reading about animal training and evolutionary biology and whatnot, because i have a new puppy", "i adopted a rescue puppy", "and it's called chimpanzee politics: power and sex among apes, written by franz de wall, w-a-l-l", "and this book apparently was used by, and i think he's mentioned this publicly several times, newton gingrich in amassing power and overcoming opponents in his political careerso i think the parallels are fascinating", "and it's easy to convince ourselves that we are passionate about a particular position because the position has merit, whereas in reality, i think a lot of it is just a hardwired desire to fight and dominate and be right and so on, which you could trace back to chimpanzee behavior, find parallels", "and it's depressing, but i think also helpful at the same time", "william macaskill: yeah, it's a really useful lens, i think", "if you could have one billboard anywhere with anything on it, what would it say", "william macaskill: that's a good question", "so i think it would be outside the gates foundation, or maybe outside bill gates's house", "i don't know where that is, but in seattle, where ultimately, he's going to donate a hundred billion dollars", "and it would say, bill, you have talked, yeah", "you have spoken about the risks and potential upside from in the long run, developments of artificial general intelligence, yet you're not doing anything about it yet", "you haven't got involved", "you have the power to make a massive difference here", "you should do something about it", "i think that's what it would say", "so artificial intelligence", "generalized artificial intelligence", "william macaskill: and human level, greater than human level artificial intelligence", "ah", "i did not see that coming at all", "william macaskill: you did not see that coming", "this is late on into the interview", "it's a whole other [crosstalk]", "yeah, yeah", "this is act three  william macaskill: yeah", "there's a big debate in the media", "but yeah, i think this is -!i know an oxford professor, nick boston, has written about this in a book called superintelligence", "oh yeah", "very, very famous book", "william macaskill: yeah, very important book, where sometimes, i think, it's very hard to predict the future", "sometimes i think you have a bit of an inkling into it", "you're able to make really educated guesses about what are going to be really big transformative technologies in the future", "the sort of things like development of fission", "but it has a huge potential for power, and lots of huge potential for harm through using nuclear weapons", "i think the case of development of artificial intelligence; it's not going to happen tomorrow", "but thinking about 30 years, or 50 years, or by the end of the century, it's really likely it's going to be one of the most, or the most important development of the century when it does happen", "like in the case, if we could have known about nuclear weapons or developing fission much earlier, we could have had policies in place such that we were really prepared for that", "we wouldn't have maybe had a nuclear arms race", "the world would have been a much better place", "i think that's the situation we're potentially in with developments of artificial intelligence as well, so", "okay", "so i was planning on wrapping in another two minutes, but i can't let this one go", "so you're hanging out with, you mentioned nick, superintelligence", "you're surrounded by, or you have access to some very smart people who have thought a lot about this", "it seems like you have as well", "what percentage of those who are most educated about the potential implications, ramifications of ai are strongly concerned that it's summoning the demon", "william macaskill: summoning the demon", "yeah", "i mean, summoning the demon's quite an extreme way of putting it", "well, yeah, i mean", "william macaskill: [inaudible] elon musk", "right, that's elon musk, yeah", "william macaskill: mit", "so it depends exactly on who the reference class is", "but on some accounts, its the large majority, actually, where the media just completely distorts the debate because the media loves to distort debates", "right", "william macaskill: where if you're framing it as this is a really important issue", "it's not something that's going to happen tomorrow", "it's something that's a long-term speculative issue", "but obviously, we need to have a sensible, rational approach to this, and a proactive approach such that we're aware of what's coming and have taken precautions so that we use this new technology in a way that is going to lead to good outcomes and avoid bad outcomesthen the rate of agreement is just kind of very high indeed", "if instead, you were saying something narrower, which is like, well, ai is going to happen in 20 years, and then it's going to be terminator scenario, and we're all gone for sure", "that's a much smaller percentage of people", "so let me rephrase my question, which is a totally different question, so i'm kind of cheating", "william macaskill: okay", "but so you are in a very interesting because you've had the perspective and experience of watching behave what could be considered very rationally", "in other words, they would rescue the drowning child, but they won't donate that amount of money for a similar, nearly guaranteed outcome, right", "and then you have, for instance - this is more from my experience, but i've had a lot of exposure to lawyers and attorneys in the legal world over the last decade or so", "and you'll find people who are genuinely, i would say, good people, who started out with very altruistic, world-improving agendas", "and yet now, they are, say, defending child molesters in the catholic church", "and their job is to find holes in the depositions of these victims", "i mean, it sounds fucking terrible, and it is", "or their job is to help big oil companies avoid lawsuits and problematic legislation when there are violations of epa regulations, right", "i mean, from my perspective, just horrific, evil shit", "and they're able to rationalize doing it, right", "everyone is entitled to due process, right", "that's kind of the catchall brush aside that you hear", "and but it's like they go from that to a point where - this is maybe a separate podcast, but i'm all fired up now", "they go from being a hesitant participant in that to maybe now they're a senior partner, and they're like, oh, there's an oil spill", "fantastic", "can you imagine how much work we're going to have now, right?iand these are people who, outside of that compartmentalization, act in very good ways", "so i guess part of my concern, or it's not a concern, but my question for you is, given how you've observed these quirks of human nature, do you think people who are the forefront of ai who have the possibility of changing the world in such a fundamental way, not only for other people, but to generate wealth that is almost beyond comprehension for themselves", "do you think that drive and greed and arms race, because there are competing teams, right, trying to get to this point in many countries, where you have a generalized artificial intelligence", "do you think that that competitive drive and desire to win and generate wealth, etc., will override the voice in the back of their head saying you need to figure out the safety precautions and the safety net before we get anywhere close to this technology taking off", "in the same way that you talked about the nuclear arms race, right", "what's your perspective", "william macaskill: yeah", "so sadly, i mean, this is just a classic tragedy of the commons, where if you're going to have multiple people trying to build the same thing, and where whoever gets there first wins, basically, just has much more power", "and then some people think, oh yeah, we should be doing this more cautiously", "that would slow progress, but we'd be having a greater chance of positive upside and fewer risks", "and then they're just going to kind of lose the race", "and yeah, sadly, i think it's not - and maybe you can even have that, even if everyone's acting altruistically, maybe they disagree slightly on how things should be done, and that's enough for them kind of not to trust each other and the absence of coordination", "and there, again, it's just not even a matter of people getting corrupted, perhaps, as you talk about the lawyers being happy about an oil spill, but just as a matter of economic incentives", "and you can get these race dynamics", "and that was exactly the case between the us and russia with nuclear weapons", "i'm definitely not saying it's a perfect analogy at all, but there, there was the battle plan, which was a proposal after the second world war for kind of complete abandonment of all nuclear weapons, and all fission material would be kind of kept a check on by the united nations", "and basically, all parties were in favor of this because it's the best outcome for everyone", "but it still wasn't able to happen because there wasn't sufficient trust between two countries", "and then we get this incentive, this kind of arms race", "and that's, i think, why we kind of want not just ai", "other sort of risky technologies as well", "the ability to develop pathogens, the ability to do gene engineering", "we're on the frontier of developing many different technologies that have very large potential upsides and very large potential costs", "and in each case, we want to have a coordinated approach so that we can ensure that we don't get those sort of race dynamics, i think", "what existential threat to mankind worries you the most, or is most underrated", "those are two different questions, but i'll make it two questions anyway", "william macaskill: yeah", "so i guess until recently, i would have said - actually, yeah, okay", "i have an answer for most underrated", "so what is going to be the most", "so the development of new pathogens", "so once we start being able to build viruses and bacteria, then it will become very easy to potentially build pathogens that could kill billions of people around the entire world, or just almost everyone in the worldthat's very worrying, as is ai", "those are the two big ones, i thinkin terms of most underrated, i think, are the ones we don't even know about", "right", "william macaskill: predicting future technology is extremely difficult to do", "everyone basically agrees with this", "and many of the developments that have happened over the last 50, 100 years would have been completely unpredictable 50 or 100 years before that", "and we should expect, again, there's going to be developments that happen over the next 50, 100 years that no one's even thought of at the moment", "and so i think that means - but you can still make some sort of progress on mitigating those risksbecause there are some things you can do, like greater political coordination across the world is just going to be really good across a very wide range of scenarios", "having research institutes, working on the frontiers of technological development, doing horizon scanning to try and identify sort of risks like this", "those are some of the things that we could be doing to try and mitigate these unknown unknowns", "that's exactly the sort of thing we're going to be biased against because it's like, you're spending money doing something that you don't even know what it's going to help with", "how is that going to sell", "so i suspect the biggest risks are ones we haven't even thought of.right", "yeah, the black swans", "just a couple more questions", "what advice would you give to your - you're only 28, so what advice would you give to your 20-year-old self", "william macaskill: to my 20-year-old self", "yeah, let's see", "the two, i think - so one is emphasizing that you have 80,000 working hours in the course of your life", "it's incredibly important to work out how best to spend them", "and what you're doing at the moment, 20-year-old will, is just kind of drifting and thinking, and not spending very much time thinking about this kind of macro optimization", "you might be thinking about, how can i do my coursework as well as possible and micro optimization, but not really thinking about, okay, what are actually my ultimate goals in life, and how can i optimize towards them", "an analogy i use is, if you're going out for dinner, it's going to take you a couple of hours", "you spend five minutes working out where to go for dinner", "it seems reasonable to spend sort of five percent of your time on how to spend the remaining 95 percent", "if you did that with your career, that would be 4000 hours, or two working years", "and actually, i think that's a pretty legitimate thing to do, spending that length of time trying to work out how should you be spending the rest of your life", "now, are those two contiguous years, or are those four years of total time divided", "william macaskill: yeah, i think four years of total time weighted towards the front of your career, i think", "i think we should be spending a lot of time, and i do this", "any sort of big decision i make, i spend a very large amount of time thinking about, is this the best thing that i could be doing", "what other things could i be doing instead", "are there ways i can change my plans", "what's your process for thinking that through", "do you sit down with a particular pad of paper and go through a particular set of questions", "what is the thinking process for important, big decisions", "william macaskill: yeahso i create a google doc that i share with friends, or people who i particularly respect, who then provide comments, and there will often be several different iterations of this", "and there's a framework", "so the [inaudible] 80,000 hours pretty much as well, where - because i'm thinking about the impact i can ultimately make", "you can break that down into three components", "impact you'll have - so this is for job decisions, but it actually applies quite widely", "impact you'll have on the job", "so you can think about impact you'll have through your direct labor, through your ability to advocate for important causes, through your donations as well", "but then also impact later on in life, where that's skills, credentials, network", "then also, how does this keep my options open", "so academia is a great example of this", "if you leave academia, it's very hard to come back", "whereas if you go and do something before going into academia or doing a phd, it's easy to transition back in", "similarly, if you go into a for-profit, then you can transition to nonprofits quite easily", "much harder to do it vice versa", "and then also how much you learn about yourself in the course of this work", "then the third aspect is personal fit", "so how uniquely good am i at doing this compared to other people", "and so that's a kind of framework, basically just a big checklist", "values, if i'm evaluating different sorts of large-scale pieces of work i could be doing", "can people find this framework on the 80,000 hours website", "william macaskill: yes, on the 80,000 hours website, you'll get it kind of as soon as you go in", "there's -  what is the website", "william macaskill: so just 80000hours.org", "80,000 the number, hours.org", "and then there's a career guide, and actually, we've kind of built an interactive tool to help you apply this framework in your own career decisions", "it takes about 30 minutes to do, for how to choose that", "and we'll also kind of recommend you ideas as you go through", "because i think we don't often think about this in a very structured way at all  no", "william macaskill: and it's the most important decision of our lives", "i think i'm going to do that in the next 24 to 48 hours because i have a habit of just, at random moments, i'll have two glasses of wine and ask my girlfriend, \"what should i do with my life", "what do you think?\" i mean, i'm playing a little bit", "i mean, it's not the only way that i approach trying to make these decisions", "but i haven't had a structured way of assessing impact of some of these larger options", "and i think how -william macaskill: if you want any career advice as well, we do specialize in that, so i'm happy to give you a one-on-one", "i appreciate it", "i'm not sure if you could consider anything i've done a career, but", "william macaskill: well, that's the thing, actually", "that's one of the mistakes we think people make, is thinking about careers", "really, you should just be thinking about stages in your life, because very few people nowadays just do one thing and then stick at it for the rest of their life", "yeah, definitely", "william macaskill: and you want to be much more flexible than that", "yeah", "and keeping the options open is a really interesting pointwe're going to wrap up in a minute, so we won't get into it in this particular conversation", "but i spoke a lot with scott adams, the creator of dilbert, about this and how he approaches his life from what he calls a systems perspective, as opposed to a goals perspective", "and the systems is always, in effect, ensuring that even if a given project or stage fails, the skills and relationships and so on that he develops in addition to the way in which he sequenced things, like you mentioned, allows him to be as good off, as well off or better off afterwards", "even if it's a strikeout on some other levels", "this is the last question", "what ask or request do you have of people listening", "i mean, i'm going to throw it out there just to - because it addresses a pet peeve of mine", "if you're a founder who claims to be building something to change the world, and if you're not able or not willing to contribute to any causes right now, then sign the founder's pledge", "two percent is nothing", "it's $2000 out of a million dollars", "it's nothing", "it's trivial", "so i would just say, if that's your line, make sure you're not lying to yourself and other people", "just sign the pledge", "i don't see any downside to it that i can perceive", "so that would be one ask of mine", "but what would your ask or request be to the audience, and where can they learn more about what you're up to and find your work online, and you, for that matter", "william macaskill: great", "so, key ask is go to effectivealtruism.com", "and you can sign up for the effective altruism newsletter there", "there's also, if you're interested, you can buy my book on there as well, doing good better, that's all about the ideas we talked about", "at least some of the ideas we talked about, about doing the most goodbeyond that, if you want to do good with charities, see giveworld.org for top recommended charitiesif you want to do good for your career choice, 80000hours.org", "again, sign up for the newsletter", "and if you're really feeling inspired and you want to make an even bigger commitment than that founder's pledge, giving what we can is a pledge of 10 percent or more", "and you can join the community, and it's a really kind of worthwhile thing to do that will make your life more meaningful and also have a huge impact at the same time", "but the key of those is effectivealtruism.com", "and will, how do you pronounce your last name correctly", "william macaskill: macaskill", "okay", "and so for people who are going to misspell this, if you wanted to say hi to will on twitter, it's @willmacaskill, m-a-c-a-s-k-i-l-l", "so kind of like mac a skill, i guess, if you wanted to try to split those up", "but will macaskill", "and then facebook is facebook.com/wdcrouch", "that's a whole separate question that i want to get into", "and then linkedin and so on", "and for everybody listening, of course, the links that we discussed, the links that will just mentioned, those will all be in the show notes", "the books, the movies, the wild weekends with louie theroux will all be found at fourhourworkweek.com, spell it all outfourhourworkweek.com/podcast", "and will, this has been great fun", "i really appreciate you taking the time", "william macaskill: yeah, i've really enjoyed it", "thank you", "thanks", "and everybody listening, thank you for listening", "and until next time, please experiment often, consider the impact of what you're doing", "don't misspend your 80,000 hours", "and check it out, 80000hours.org and everything else that will mentionedthanks so much", "hey guys, this is tim again", "just a few more things before you take off", "number one, this is five bullet friday", "do you want to get a short email from me", "would you enjoy getting a short email from me every friday that provides a little more sort of fun before the weekend", "five bullet friday is a very short email where i share the coolest things i've found, or that i've been pondering over the week", "that could include favorite new albums that i've discovered, it could include gizmos and gadgets and all sorts of weird shit that i've somehow dug up in the world of the esoteric, as i do   it could include favorite articles that i've read and that i've shared with my close friends, for instance", "and it's very short", "it's just a little tiny byte of goodness before you head off for the weekendso if you want to receive that, check it out", "just go to fourhourworkweek.com", "that's fourhourworkweek.com, all spelled out, and just drop in your email, and you will get the very next one", "and if you sign up, i hope you enjoy it."]}